{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Video Actor Synchroncy and Causality (VASC)\n",
    "## RAEng: Measuring Responsive Caregiving Project\n",
    "### Caspar Addyman, 2020\n",
    "### https://github.com/infantlab/VASC\n",
    "\n",
    "# Step 1  Process videos using OpenPose\n",
    "\n",
    "This script uses [OpenPose](https://github.com/CMU-Perceptual-Computing-Lab/openpose) human figure recognition neural network to create labeled wireframes for each figure in each frame of a video. OpenPoseDemo will go through a video frame by frame outputing a JSON file for each frame that contains a set of coordinate points and for a wireframe for each video."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.1 - Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Automatic pdb calling has been turned ON\n"
     ]
    }
   ],
   "source": [
    "#import the python libraries we need\n",
    "import os\n",
    "import sys\n",
    "import time\n",
    "import glob\n",
    "import json\n",
    "import cv2               #computervision toolkit\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "\n",
    "\n",
    "#turn on debugging\n",
    "%pdb on"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 Where is OpenPose?\n",
    "\n",
    "We need the full path to your openpose directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\cas\\openpose-1.5.0-binaries-win64-gpu-python-flir-3d_recommended\\bin\\OpenPoseDemo.exe\n"
     ]
    }
   ],
   "source": [
    "# location of openposedemo - THIS WILL BE DIFFERENT ON YOUR COMPUTER\n",
    "openposepath = \"C:\\\\Users\\\\cas\\\\openpose-1.5.0-binaries-win64-gpu-python-flir-3d_recommended\\\\\"\n",
    "#openposepath = \"C:\\\\Users\\\\caspar\\\\openpose-1.4.0-win64-cpu-binaries\\\\\"\n",
    "\n",
    "if sys.platform == \"win32\":\n",
    "    app = \"bin\\\\OpenPoseDemo.exe\"\n",
    "else:\n",
    "    app = 'bin\\\\OpenPoseDemo.bin'\n",
    "\n",
    "openposeapp = openposepath + app\n",
    "print(openposeapp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3 Where are your videos?\n",
    "\n",
    "In the next cell you need to specify the folder with your set of video files. So that we process them. These scripts use the following director structure. It expects your videos to be in a subfolder of your project \n",
    "\n",
    "```\n",
    "path\\to\\project\\myvideos\n",
    "```\n",
    "\n",
    "and then it creates a folder `out` in the project at the same level as the videos with three subfolders for JSON files, the aggregated timeseries and the analyses\n",
    "\n",
    "```\n",
    "path\\to\\project\\out\\openpose\n",
    "path\\to\\project\\out\\timeseries\n",
    "path\\to\\project\\out\\analyses\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Cas\\OneDrive - Goldsmiths College\\Projects\\Measuring Responsive Caregiving\\lookit\\\n",
      "C:\\Users\\Cas\\OneDrive - Goldsmiths College\\Projects\\Measuring Responsive Caregiving\\lookit\\out\n",
      "C:\\Users\\Cas\\OneDrive - Goldsmiths College\\Projects\\Measuring Responsive Caregiving\\lookit\\out\\openpose\n",
      "C:\\Users\\Cas\\OneDrive - Goldsmiths College\\Projects\\Measuring Responsive Caregiving\\lookit\\out\\timeseries\n",
      "C:\\Users\\Cas\\OneDrive - Goldsmiths College\\Projects\\Measuring Responsive Caregiving\\lookit\\out\\analyses\n"
     ]
    }
   ],
   "source": [
    "# where's the project folder? (with trailing slash)\n",
    "# projectpath = os.getcwd() + \"\\\\..\\\\lookit\\\\\"\n",
    "projectpath = \"C:\\\\Users\\\\Cas\\\\OneDrive - Goldsmiths College\\\\Projects\\\\Measuring Responsive Caregiving\\\\lookit\\\\\"\n",
    "\n",
    "# locations of videos and output\n",
    "videos_in = projectpath \n",
    "videos_out   = projectpath + \"out\"\n",
    "videos_out_openpose   = videos_out + \"\\\\openpose\"\n",
    "videos_out_timeseries = videos_out + \"\\\\timeseries\"\n",
    "videos_out_analyses   = videos_out + \"\\\\analyses\"\n",
    "\n",
    "print(videos_in)\n",
    "print(videos_out)\n",
    "print(videos_out_openpose)\n",
    "print(videos_out_timeseries)\n",
    "print(videos_out_analyses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We found 0 avis\n",
      "We found 10 mp4s\n"
     ]
    }
   ],
   "source": [
    "#first get list of videos in the inbox\n",
    "avis = glob.glob(videos_in + \"*.avi\")\n",
    "mp4s = glob.glob(videos_in + \"*.mp4\")\n",
    "\n",
    "print(\"We found %d avis\" % len(avis))\n",
    "print(\"We found %d mp4s\" % len(mp4s))\n",
    "\n",
    "#For the moment we will manually specify what videos to process. \n",
    "#TODO generate a list of force or skip videos to automate things slightly\n",
    "allvideos = []\n",
    "allvideos.extend(avis)\n",
    "allvideos.extend(mp4s)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.4 Calling the OpenPose app\n",
    "To operate OpenPose we pass a set of parameters to the demo executable. For the full list of options see  [OpenPoseDemo](https://github.com/CMU-Perceptual-Computing-Lab/openpose/blob/master/doc/demo_overview.md)\n",
    "\n",
    "Our main parameters are\n",
    "\n",
    "```\n",
    "--video        path\\to\\video_to_process   #input video\n",
    "--write_json   path\\to\\output_directory   #one json file per frame\n",
    "--write_video  path\\to\\output_directory   #video with identified figures\n",
    "--write_images path\\to\\output_directory   #one image per frame with wireframes\n",
    "--disable_blending true/false             # wireframes on black background (true) or blended on top of video (false)\n",
    " ```\n",
    "\n",
    "Other useful params\n",
    " ```\n",
    "--frame_first  100    #start from frame 100\n",
    "--display 0           #don't show the images as they are processed\n",
    " ```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "#put all params in a dictionary object\n",
    "params = dict()\n",
    "params[\"write_json\"] = videos_out_openpose\n",
    "params[\"write_images\"] = videos_out_openpose  #for the moment dump images in output file - TODO name subfolder\n",
    "params[\"disable_blending\"] = \"true\"\n",
    "params[\"display\"]  = \"1\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The main openpose loop\n",
    "\n",
    "Call the openpose app for each of the videos at a time. For each one print the full command that we use so that you can use it manually to investigate any errors. \n",
    "\n",
    "Finally, we write a list of the processed videos to a file called `videos.json`. \n",
    "Note that we will add other information to this file as we go through other steps. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " --write_json \"C:\\Users\\Cas\\OneDrive - Goldsmiths College\\Projects\\Measuring Responsive Caregiving\\lookit\\out\\openpose\" --write_images \"C:\\Users\\Cas\\OneDrive - Goldsmiths College\\Projects\\Measuring Responsive Caregiving\\lookit\\out\\openpose\" --disable_blending \"true\" --display \"1\"\n",
      "\n",
      "\n",
      "Staring openpose processing of C:\\Users\\Cas\\OneDrive - Goldsmiths College\\Projects\\Measuring Responsive Caregiving\\lookit\\lookit.01.mp4\n",
      "C:\\Users\\cas\\openpose-1.5.0-binaries-win64-gpu-python-flir-3d_recommended\\bin\\OpenPoseDemo.exe --video \"C:\\Users\\Cas\\OneDrive - Goldsmiths College\\Projects\\Measuring Responsive Caregiving\\lookit\\lookit.01.mp4\" --write_video \"C:\\Users\\Cas\\OneDrive - Goldsmiths College\\Projects\\Measuring Responsive Caregiving\\lookit\\out\\openpose\\lookit.01_output.avi\" --write_json \"C:\\Users\\Cas\\OneDrive - Goldsmiths College\\Projects\\Measuring Responsive Caregiving\\lookit\\out\\openpose\" --write_images \"C:\\Users\\Cas\\OneDrive - Goldsmiths College\\Projects\\Measuring Responsive Caregiving\\lookit\\out\\openpose\" --disable_blending \"true\" --display \"1\"\n",
      "Done C:\\Users\\Cas\\OneDrive - Goldsmiths College\\Projects\\Measuring Responsive Caregiving\\lookit\\lookit.01.mp4\n",
      "It took 19 seconds for conversion.\n",
      "\n",
      "\n",
      "Staring openpose processing of C:\\Users\\Cas\\OneDrive - Goldsmiths College\\Projects\\Measuring Responsive Caregiving\\lookit\\lookit.02.mp4\n",
      "C:\\Users\\cas\\openpose-1.5.0-binaries-win64-gpu-python-flir-3d_recommended\\bin\\OpenPoseDemo.exe --video \"C:\\Users\\Cas\\OneDrive - Goldsmiths College\\Projects\\Measuring Responsive Caregiving\\lookit\\lookit.02.mp4\" --write_video \"C:\\Users\\Cas\\OneDrive - Goldsmiths College\\Projects\\Measuring Responsive Caregiving\\lookit\\out\\openpose\\lookit.02_output.avi\" --write_json \"C:\\Users\\Cas\\OneDrive - Goldsmiths College\\Projects\\Measuring Responsive Caregiving\\lookit\\out\\openpose\" --write_images \"C:\\Users\\Cas\\OneDrive - Goldsmiths College\\Projects\\Measuring Responsive Caregiving\\lookit\\out\\openpose\" --disable_blending \"true\" --display \"1\"\n",
      "Done C:\\Users\\Cas\\OneDrive - Goldsmiths College\\Projects\\Measuring Responsive Caregiving\\lookit\\lookit.02.mp4\n",
      "It took 11 seconds for conversion.\n",
      "\n",
      "\n",
      "Staring openpose processing of C:\\Users\\Cas\\OneDrive - Goldsmiths College\\Projects\\Measuring Responsive Caregiving\\lookit\\lookit.03.mp4\n",
      "C:\\Users\\cas\\openpose-1.5.0-binaries-win64-gpu-python-flir-3d_recommended\\bin\\OpenPoseDemo.exe --video \"C:\\Users\\Cas\\OneDrive - Goldsmiths College\\Projects\\Measuring Responsive Caregiving\\lookit\\lookit.03.mp4\" --write_video \"C:\\Users\\Cas\\OneDrive - Goldsmiths College\\Projects\\Measuring Responsive Caregiving\\lookit\\out\\openpose\\lookit.03_output.avi\" --write_json \"C:\\Users\\Cas\\OneDrive - Goldsmiths College\\Projects\\Measuring Responsive Caregiving\\lookit\\out\\openpose\" --write_images \"C:\\Users\\Cas\\OneDrive - Goldsmiths College\\Projects\\Measuring Responsive Caregiving\\lookit\\out\\openpose\" --disable_blending \"true\" --display \"1\"\n",
      "Done C:\\Users\\Cas\\OneDrive - Goldsmiths College\\Projects\\Measuring Responsive Caregiving\\lookit\\lookit.03.mp4\n",
      "It took 11 seconds for conversion.\n",
      "\n",
      "\n",
      "Staring openpose processing of C:\\Users\\Cas\\OneDrive - Goldsmiths College\\Projects\\Measuring Responsive Caregiving\\lookit\\lookit.04.mp4\n",
      "C:\\Users\\cas\\openpose-1.5.0-binaries-win64-gpu-python-flir-3d_recommended\\bin\\OpenPoseDemo.exe --video \"C:\\Users\\Cas\\OneDrive - Goldsmiths College\\Projects\\Measuring Responsive Caregiving\\lookit\\lookit.04.mp4\" --write_video \"C:\\Users\\Cas\\OneDrive - Goldsmiths College\\Projects\\Measuring Responsive Caregiving\\lookit\\out\\openpose\\lookit.04_output.avi\" --write_json \"C:\\Users\\Cas\\OneDrive - Goldsmiths College\\Projects\\Measuring Responsive Caregiving\\lookit\\out\\openpose\" --write_images \"C:\\Users\\Cas\\OneDrive - Goldsmiths College\\Projects\\Measuring Responsive Caregiving\\lookit\\out\\openpose\" --disable_blending \"true\" --display \"1\"\n",
      "Done C:\\Users\\Cas\\OneDrive - Goldsmiths College\\Projects\\Measuring Responsive Caregiving\\lookit\\lookit.04.mp4\n",
      "It took 22 seconds for conversion.\n",
      "\n",
      "\n",
      "Staring openpose processing of C:\\Users\\Cas\\OneDrive - Goldsmiths College\\Projects\\Measuring Responsive Caregiving\\lookit\\lookit.05.mp4\n",
      "C:\\Users\\cas\\openpose-1.5.0-binaries-win64-gpu-python-flir-3d_recommended\\bin\\OpenPoseDemo.exe --video \"C:\\Users\\Cas\\OneDrive - Goldsmiths College\\Projects\\Measuring Responsive Caregiving\\lookit\\lookit.05.mp4\" --write_video \"C:\\Users\\Cas\\OneDrive - Goldsmiths College\\Projects\\Measuring Responsive Caregiving\\lookit\\out\\openpose\\lookit.05_output.avi\" --write_json \"C:\\Users\\Cas\\OneDrive - Goldsmiths College\\Projects\\Measuring Responsive Caregiving\\lookit\\out\\openpose\" --write_images \"C:\\Users\\Cas\\OneDrive - Goldsmiths College\\Projects\\Measuring Responsive Caregiving\\lookit\\out\\openpose\" --disable_blending \"true\" --display \"1\"\n",
      "Done C:\\Users\\Cas\\OneDrive - Goldsmiths College\\Projects\\Measuring Responsive Caregiving\\lookit\\lookit.05.mp4\n",
      "It took 24 seconds for conversion.\n",
      "\n",
      "\n",
      "Staring openpose processing of C:\\Users\\Cas\\OneDrive - Goldsmiths College\\Projects\\Measuring Responsive Caregiving\\lookit\\lookit.06.mp4\n",
      "C:\\Users\\cas\\openpose-1.5.0-binaries-win64-gpu-python-flir-3d_recommended\\bin\\OpenPoseDemo.exe --video \"C:\\Users\\Cas\\OneDrive - Goldsmiths College\\Projects\\Measuring Responsive Caregiving\\lookit\\lookit.06.mp4\" --write_video \"C:\\Users\\Cas\\OneDrive - Goldsmiths College\\Projects\\Measuring Responsive Caregiving\\lookit\\out\\openpose\\lookit.06_output.avi\" --write_json \"C:\\Users\\Cas\\OneDrive - Goldsmiths College\\Projects\\Measuring Responsive Caregiving\\lookit\\out\\openpose\" --write_images \"C:\\Users\\Cas\\OneDrive - Goldsmiths College\\Projects\\Measuring Responsive Caregiving\\lookit\\out\\openpose\" --disable_blending \"true\" --display \"1\"\n",
      "Done C:\\Users\\Cas\\OneDrive - Goldsmiths College\\Projects\\Measuring Responsive Caregiving\\lookit\\lookit.06.mp4\n",
      "It took 15 seconds for conversion.\n",
      "\n",
      "\n",
      "Staring openpose processing of C:\\Users\\Cas\\OneDrive - Goldsmiths College\\Projects\\Measuring Responsive Caregiving\\lookit\\lookit.07.mp4\n",
      "C:\\Users\\cas\\openpose-1.5.0-binaries-win64-gpu-python-flir-3d_recommended\\bin\\OpenPoseDemo.exe --video \"C:\\Users\\Cas\\OneDrive - Goldsmiths College\\Projects\\Measuring Responsive Caregiving\\lookit\\lookit.07.mp4\" --write_video \"C:\\Users\\Cas\\OneDrive - Goldsmiths College\\Projects\\Measuring Responsive Caregiving\\lookit\\out\\openpose\\lookit.07_output.avi\" --write_json \"C:\\Users\\Cas\\OneDrive - Goldsmiths College\\Projects\\Measuring Responsive Caregiving\\lookit\\out\\openpose\" --write_images \"C:\\Users\\Cas\\OneDrive - Goldsmiths College\\Projects\\Measuring Responsive Caregiving\\lookit\\out\\openpose\" --disable_blending \"true\" --display \"1\"\n",
      "Done C:\\Users\\Cas\\OneDrive - Goldsmiths College\\Projects\\Measuring Responsive Caregiving\\lookit\\lookit.07.mp4\n",
      "It took 18 seconds for conversion.\n",
      "\n",
      "\n",
      "Staring openpose processing of C:\\Users\\Cas\\OneDrive - Goldsmiths College\\Projects\\Measuring Responsive Caregiving\\lookit\\lookit.08.mp4\n",
      "C:\\Users\\cas\\openpose-1.5.0-binaries-win64-gpu-python-flir-3d_recommended\\bin\\OpenPoseDemo.exe --video \"C:\\Users\\Cas\\OneDrive - Goldsmiths College\\Projects\\Measuring Responsive Caregiving\\lookit\\lookit.08.mp4\" --write_video \"C:\\Users\\Cas\\OneDrive - Goldsmiths College\\Projects\\Measuring Responsive Caregiving\\lookit\\out\\openpose\\lookit.08_output.avi\" --write_json \"C:\\Users\\Cas\\OneDrive - Goldsmiths College\\Projects\\Measuring Responsive Caregiving\\lookit\\out\\openpose\" --write_images \"C:\\Users\\Cas\\OneDrive - Goldsmiths College\\Projects\\Measuring Responsive Caregiving\\lookit\\out\\openpose\" --disable_blending \"true\" --display \"1\"\n",
      "Done C:\\Users\\Cas\\OneDrive - Goldsmiths College\\Projects\\Measuring Responsive Caregiving\\lookit\\lookit.08.mp4\n",
      "It took 15 seconds for conversion.\n",
      "\n",
      "\n",
      "Staring openpose processing of C:\\Users\\Cas\\OneDrive - Goldsmiths College\\Projects\\Measuring Responsive Caregiving\\lookit\\lookit.09.mp4\n",
      "C:\\Users\\cas\\openpose-1.5.0-binaries-win64-gpu-python-flir-3d_recommended\\bin\\OpenPoseDemo.exe --video \"C:\\Users\\Cas\\OneDrive - Goldsmiths College\\Projects\\Measuring Responsive Caregiving\\lookit\\lookit.09.mp4\" --write_video \"C:\\Users\\Cas\\OneDrive - Goldsmiths College\\Projects\\Measuring Responsive Caregiving\\lookit\\out\\openpose\\lookit.09_output.avi\" --write_json \"C:\\Users\\Cas\\OneDrive - Goldsmiths College\\Projects\\Measuring Responsive Caregiving\\lookit\\out\\openpose\" --write_images \"C:\\Users\\Cas\\OneDrive - Goldsmiths College\\Projects\\Measuring Responsive Caregiving\\lookit\\out\\openpose\" --disable_blending \"true\" --display \"1\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done C:\\Users\\Cas\\OneDrive - Goldsmiths College\\Projects\\Measuring Responsive Caregiving\\lookit\\lookit.09.mp4\n",
      "It took 17 seconds for conversion.\n",
      "\n",
      "\n",
      "Staring openpose processing of C:\\Users\\Cas\\OneDrive - Goldsmiths College\\Projects\\Measuring Responsive Caregiving\\lookit\\lookit.10.mp4\n",
      "C:\\Users\\cas\\openpose-1.5.0-binaries-win64-gpu-python-flir-3d_recommended\\bin\\OpenPoseDemo.exe --video \"C:\\Users\\Cas\\OneDrive - Goldsmiths College\\Projects\\Measuring Responsive Caregiving\\lookit\\lookit.10.mp4\" --write_video \"C:\\Users\\Cas\\OneDrive - Goldsmiths College\\Projects\\Measuring Responsive Caregiving\\lookit\\out\\openpose\\lookit.10_output.avi\" --write_json \"C:\\Users\\Cas\\OneDrive - Goldsmiths College\\Projects\\Measuring Responsive Caregiving\\lookit\\out\\openpose\" --write_images \"C:\\Users\\Cas\\OneDrive - Goldsmiths College\\Projects\\Measuring Responsive Caregiving\\lookit\\out\\openpose\" --disable_blending \"true\" --display \"1\"\n",
      "Done C:\\Users\\Cas\\OneDrive - Goldsmiths College\\Projects\\Measuring Responsive Caregiving\\lookit\\lookit.10.mp4\n",
      "It took 17 seconds for conversion.\n"
     ]
    }
   ],
   "source": [
    "currdir =  os.getcwd() + \"\\\\\" #keep track of current directory so we can change back to it after processing\n",
    "\n",
    "optstring = \"\"\n",
    "for key in params:\n",
    "    optstring += \" --\" + key +  ' \"' + params[key] + '\"' #need to quote paths \n",
    "\n",
    "print(optstring)\n",
    "\n",
    "videos = {}\n",
    "count = 0\n",
    "os.chdir(openposepath)\n",
    "for vid in allvideos:\n",
    "    #first we need base name of video for the output file name\n",
    "    fullname = os.path.basename(vid)\n",
    "    base, fmt = os.path.splitext(fullname)\n",
    "    video_outname = base + \"_output.avi\"\n",
    "    #log some info about this video\n",
    "    videos[base] = {}\n",
    "    videos[base][\"fullname\"] = fullname\n",
    "    videos[base][\"fullpath\"] = vid\n",
    "    videos[base][\"index\"] = None         #the numerical index this data will have in np.array.\n",
    "    videos[base][\"format\"] = fmt\n",
    "    videos[base][\"openpose\"] =  {\"exitcode\" : None, \"when\" : None} \n",
    "    \n",
    "    print(\"\\n\\nStaring openpose processing of \" + vid)\n",
    "    try:\n",
    "        # Log the time\n",
    "        time_start = time.time()\n",
    "        video = ' --video \"' + vid + '\"'\n",
    "        video_out = ' --write_video \"' + videos_out_openpose + '\\\\' + video_outname + '\"'\n",
    "        opbin = openposeapp + video + video_out + optstring\n",
    "        print(opbin)\n",
    "        exitcode = os.system(opbin)\n",
    "        videos[base][\"openpose\"][\"exitcode\"] = exitcode\n",
    "        # Log the time again\n",
    "        time_end = time.time()\n",
    "        if (exitcode == 0):\n",
    "            videos[base][\"index\"] = count  #TODO - Use this \n",
    "            count += 1\n",
    "            videos[base][\"openpose\"][\"when\"] = datetime.now().isoformat()\n",
    "            videos[base][\"openpose\"][\"out\"] = videos_out_openpose + '\\\\' + video_outname\n",
    "            print (\"Done \" + vid)\n",
    "            print (\"It took %d seconds for conversion.\" % (time_end-time_start))\n",
    "        else:\n",
    "            print(\"OpenPose error. Exit code %d\" % exitcode)\n",
    "    except Exception as e:\n",
    "        print(\"Error: \", e)\n",
    "        pass\n",
    "    \n",
    "#change the directory back\n",
    "os.chdir(currdir)\n",
    "    \n",
    "#now we've finished, write a list of processed videos to a file\n",
    "with open(videos_out + '\\\\videos.json', 'w') as outfile:\n",
    "    json.dump(videos, outfile)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.5 Gather the data into useable format.\n",
    "\n",
    "OpenPose has created one JSON file per frame of video. We want to group these up into bigger arrays. \n",
    "\n",
    "This routine needs to know where to find the processed videos and what are the base names. These are listed in the `videos.json` file we created."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "#retrieve the list of base names of processed videos.\n",
    "with open(videos_out + '\\\\videos.json') as json_file:\n",
    "    videos = json.load(json_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First find out the height, width and frames per second for each video and add this to `videos.json`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "#make a note of some video properties\n",
    "\n",
    "for vid in videos:\n",
    "    cap = cv2.VideoCapture(videos[vid][\"fullpath\"]) # 0=camera\n",
    "    if cap.isOpened(): \n",
    "        videos[vid][\"height\"] = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "        videos[vid][\"width\"] = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "        videos[vid][\"fps\"] = int(cap.get(cv2.CAP_PROP_FPS))\n",
    "        videos[vid][\"n_frames\"] = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "    cap.release()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lookit.01\n",
      "{'fullname': 'lookit.01.mp4', 'fullpath': 'C:\\\\Users\\\\Cas\\\\OneDrive - Goldsmiths College\\\\Projects\\\\Measuring Responsive Caregiving\\\\lookit\\\\lookit.01.mp4', 'index': 0, 'format': '.mp4', 'openpose': {'exitcode': 0, 'when': '2020-02-24T10:33:45.063115', 'out': 'C:\\\\Users\\\\Cas\\\\OneDrive - Goldsmiths College\\\\Projects\\\\Measuring Responsive Caregiving\\\\lookit\\\\out\\\\openpose\\\\lookit.01_output.avi'}, 'height': 480, 'width': 640, 'fps': 15, 'n_frames': 162}\n",
      "lookit.02\n",
      "{'fullname': 'lookit.02.mp4', 'fullpath': 'C:\\\\Users\\\\Cas\\\\OneDrive - Goldsmiths College\\\\Projects\\\\Measuring Responsive Caregiving\\\\lookit\\\\lookit.02.mp4', 'index': 1, 'format': '.mp4', 'openpose': {'exitcode': 0, 'when': '2020-02-24T10:33:56.472137', 'out': 'C:\\\\Users\\\\Cas\\\\OneDrive - Goldsmiths College\\\\Projects\\\\Measuring Responsive Caregiving\\\\lookit\\\\out\\\\openpose\\\\lookit.02_output.avi'}, 'height': 480, 'width': 640, 'fps': 19, 'n_frames': 162}\n",
      "lookit.03\n",
      "{'fullname': 'lookit.03.mp4', 'fullpath': 'C:\\\\Users\\\\Cas\\\\OneDrive - Goldsmiths College\\\\Projects\\\\Measuring Responsive Caregiving\\\\lookit\\\\lookit.03.mp4', 'index': 2, 'format': '.mp4', 'openpose': {'exitcode': 0, 'when': '2020-02-24T10:34:08.445698', 'out': 'C:\\\\Users\\\\Cas\\\\OneDrive - Goldsmiths College\\\\Projects\\\\Measuring Responsive Caregiving\\\\lookit\\\\out\\\\openpose\\\\lookit.03_output.avi'}, 'height': 480, 'width': 640, 'fps': 13, 'n_frames': 164}\n",
      "lookit.04\n",
      "{'fullname': 'lookit.04.mp4', 'fullpath': 'C:\\\\Users\\\\Cas\\\\OneDrive - Goldsmiths College\\\\Projects\\\\Measuring Responsive Caregiving\\\\lookit\\\\lookit.04.mp4', 'index': 3, 'format': '.mp4', 'openpose': {'exitcode': 0, 'when': '2020-02-24T10:34:31.370322', 'out': 'C:\\\\Users\\\\Cas\\\\OneDrive - Goldsmiths College\\\\Projects\\\\Measuring Responsive Caregiving\\\\lookit\\\\out\\\\openpose\\\\lookit.04_output.avi'}, 'height': 480, 'width': 640, 'fps': 29, 'n_frames': 379}\n",
      "lookit.05\n",
      "{'fullname': 'lookit.05.mp4', 'fullpath': 'C:\\\\Users\\\\Cas\\\\OneDrive - Goldsmiths College\\\\Projects\\\\Measuring Responsive Caregiving\\\\lookit\\\\lookit.05.mp4', 'index': 4, 'format': '.mp4', 'openpose': {'exitcode': 0, 'when': '2020-02-24T10:34:55.950875', 'out': 'C:\\\\Users\\\\Cas\\\\OneDrive - Goldsmiths College\\\\Projects\\\\Measuring Responsive Caregiving\\\\lookit\\\\out\\\\openpose\\\\lookit.05_output.avi'}, 'height': 480, 'width': 640, 'fps': 30, 'n_frames': 412}\n",
      "lookit.06\n",
      "{'fullname': 'lookit.06.mp4', 'fullpath': 'C:\\\\Users\\\\Cas\\\\OneDrive - Goldsmiths College\\\\Projects\\\\Measuring Responsive Caregiving\\\\lookit\\\\lookit.06.mp4', 'index': 5, 'format': '.mp4', 'openpose': {'exitcode': 0, 'when': '2020-02-24T10:35:11.741776', 'out': 'C:\\\\Users\\\\Cas\\\\OneDrive - Goldsmiths College\\\\Projects\\\\Measuring Responsive Caregiving\\\\lookit\\\\out\\\\openpose\\\\lookit.06_output.avi'}, 'height': 480, 'width': 640, 'fps': 29, 'n_frames': 229}\n",
      "lookit.07\n",
      "{'fullname': 'lookit.07.mp4', 'fullpath': 'C:\\\\Users\\\\Cas\\\\OneDrive - Goldsmiths College\\\\Projects\\\\Measuring Responsive Caregiving\\\\lookit\\\\lookit.07.mp4', 'index': 6, 'format': '.mp4', 'openpose': {'exitcode': 0, 'when': '2020-02-24T10:35:30.138330', 'out': 'C:\\\\Users\\\\Cas\\\\OneDrive - Goldsmiths College\\\\Projects\\\\Measuring Responsive Caregiving\\\\lookit\\\\out\\\\openpose\\\\lookit.07_output.avi'}, 'height': 480, 'width': 640, 'fps': 29, 'n_frames': 282}\n",
      "lookit.08\n",
      "{'fullname': 'lookit.08.mp4', 'fullpath': 'C:\\\\Users\\\\Cas\\\\OneDrive - Goldsmiths College\\\\Projects\\\\Measuring Responsive Caregiving\\\\lookit\\\\lookit.08.mp4', 'index': 7, 'format': '.mp4', 'openpose': {'exitcode': 0, 'when': '2020-02-24T10:35:45.647647', 'out': 'C:\\\\Users\\\\Cas\\\\OneDrive - Goldsmiths College\\\\Projects\\\\Measuring Responsive Caregiving\\\\lookit\\\\out\\\\openpose\\\\lookit.08_output.avi'}, 'height': 480, 'width': 640, 'fps': 29, 'n_frames': 222}\n",
      "lookit.09\n",
      "{'fullname': 'lookit.09.mp4', 'fullpath': 'C:\\\\Users\\\\Cas\\\\OneDrive - Goldsmiths College\\\\Projects\\\\Measuring Responsive Caregiving\\\\lookit\\\\lookit.09.mp4', 'index': 8, 'format': '.mp4', 'openpose': {'exitcode': 0, 'when': '2020-02-24T10:36:03.348819', 'out': 'C:\\\\Users\\\\Cas\\\\OneDrive - Goldsmiths College\\\\Projects\\\\Measuring Responsive Caregiving\\\\lookit\\\\out\\\\openpose\\\\lookit.09_output.avi'}, 'height': 480, 'width': 640, 'fps': 30, 'n_frames': 245}\n",
      "lookit.10\n",
      "{'fullname': 'lookit.10.mp4', 'fullpath': 'C:\\\\Users\\\\Cas\\\\OneDrive - Goldsmiths College\\\\Projects\\\\Measuring Responsive Caregiving\\\\lookit\\\\lookit.10.mp4', 'index': 9, 'format': '.mp4', 'openpose': {'exitcode': 0, 'when': '2020-02-24T10:36:21.183036', 'out': 'C:\\\\Users\\\\Cas\\\\OneDrive - Goldsmiths College\\\\Projects\\\\Measuring Responsive Caregiving\\\\lookit\\\\out\\\\openpose\\\\lookit.10_output.avi'}, 'height': 480, 'width': 640, 'fps': 29, 'n_frames': 259}\n"
     ]
    }
   ],
   "source": [
    "#optional\n",
    "#print these out to remind ourselves. \n",
    "for vid in videos:  \n",
    "    print(vid)\n",
    "    print(videos[vid])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  Extracting all the numeric data from the json files\n",
    "\n",
    "We loop through the list of names in `videos` and search for all json files associated with that name. We then extract all the coordinates and confidence scores for all identified people in each frame and store them in one big multidimensional padded array.\n",
    "\n",
    "```\n",
    "1st dimension - number of videos\n",
    "2nd dimension - max nummber of frames\n",
    "3rd dimension - max number of people\n",
    "4th dimension - number of values (per person) output by openpose\n",
    "```\n",
    "\n",
    "For example, if we had the following videos \n",
    "\n",
    "```\n",
    "video1 - 200 frames  - 3 people (max) \n",
    "video2 - 203 frames  - 2 people (max) \n",
    "video3 - 219 frames  - 4 people (max) \n",
    "```\n",
    "\n",
    "then we'd create a `3 x 219 x 4 x 75` array.\n",
    "\n",
    "First we see how big the first two dimensions of the array have to be. \n",
    "And create an numpy array called `keypoints_array` big enough to hold all of this.\n",
    "\n",
    "As a sanity check we count the number of frames processed by openpose. Ought to be same as above.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Video lookit.01 has 162 frames.\n",
      "Video lookit.02 has 161 frames.\n",
      "Video lookit.03 has 164 frames.\n",
      "Video lookit.04 has 379 frames.\n",
      "Video lookit.05 has 412 frames.\n",
      "Video lookit.06 has 229 frames.\n",
      "Video lookit.07 has 282 frames.\n",
      "Video lookit.08 has 222 frames.\n",
      "Video lookit.09 has 245 frames.\n",
      "Video lookit.10 has 259 frames.\n",
      "Initialise numpy array of size (10, 412, 10, 75)\n"
     ]
    }
   ],
   "source": [
    "nvideos = len(videos)\n",
    "maxframes = 0\n",
    "maxpeople = 10 #maximum people we might expect (large upper bound)\n",
    "ncoords = 75 #the length of the array coming back from openpose x,y coords of each point plus pafs\n",
    "\n",
    "for vid in videos:    \n",
    "    #use glob to get all the individual json files.\n",
    "    alljson = glob.glob(videos_out_openpose + \"\\\\\" + vid + \"*.json\")\n",
    "    nframes = len(alljson)\n",
    "    print(\"Video\", vid, \"has {0} frames.\".format(nframes))\n",
    "    videos[vid][\"frames\"] = nframes\n",
    "    maxframes = max(maxframes,nframes)\n",
    "    \n",
    "    \n",
    "keypoints_array = np.zeros([nvideos,maxframes,maxpeople,ncoords]) #big array to hold all the numbers\n",
    "print(\"Initialise numpy array of size\", keypoints_array.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now loop through all the videos copying the frame data into our big `keypoints_array` and also seeing how many people (max) are detected in each one. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Video lookit.01 has 4 people detected.\n",
      "Video lookit.02 has 2 people detected.\n",
      "Video lookit.03 has 3 people detected.\n",
      "Video lookit.04 has 3 people detected.\n",
      "Video lookit.05 has 4 people detected.\n",
      "Video lookit.06 has 4 people detected.\n",
      "Video lookit.07 has 3 people detected.\n",
      "Video lookit.08 has 3 people detected.\n",
      "Video lookit.09 has 3 people detected.\n",
      "Video lookit.10 has 3 people detected.\n",
      "keypoints_array has size (10, 412, 4, 75)\n"
     ]
    }
   ],
   "source": [
    "npeople = np.zeros(maxframes)  #an array to track how many people detected per frame.\n",
    "globalmaxpeople =  0\n",
    "\n",
    "for vid in videos:  \n",
    "    #use glob to get all the individual json files.\n",
    "    alljson = glob.glob(videos_out_openpose + \"\\\\\" + vid + \"*.json\") \n",
    "    v = videos[vid][\"index\"]\n",
    "    i = 0\n",
    "    for frame in alljson:\n",
    "        with open(frame, \"r\") as read_file:\n",
    "            data = json.load(read_file)\n",
    "            j = 0\n",
    "            for p in data[\"people\"]:\n",
    "                keypoints = p[\"pose_keypoints_2d\"]  \n",
    "                keypoints_array[v,i,j,:]=keypoints\n",
    "                j += 1\n",
    "            npeople[i] = j\n",
    "            i += 1\n",
    "    #end loop for this video\n",
    "    people = int(max(npeople))\n",
    "    print(\"Video\", vid, \"has {0} people detected.\".format(people))\n",
    "    videos[vid][\"maxpeople\"] = people\n",
    "    #how many people did it contain? Is this biggest number so far?\n",
    "    globalmaxpeople = max(globalmaxpeople, people)\n",
    "    v += 1\n",
    "    \n",
    "#and just like that n videos have been reduced to a big block of people coords.\n",
    "#we now truncate the array for the maximum number of people as the rest of it is all zeros\n",
    "\n",
    "keypoints_array = np.delete(keypoints_array,np.s_[int(globalmaxpeople):],2)\n",
    "\n",
    "print(\"keypoints_array has size\", keypoints_array.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.6 Save the data!\n",
    "\n",
    "Saving the data at this stage so we don't have to repeat these steps again if we reorganise or reanalyse the data.\n",
    "\n",
    "We create a compressed NumPy array `allframedata.npz` containing the person location data for all the videos. \n",
    "\n",
    "We also update the `videos.json` file with more info about the videos. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "#update the json file in the video out directory\n",
    "with open(videos_out + '\\\\videos.json', 'w') as outfile:\n",
    "    json.dump(videos, outfile)\n",
    "\n",
    "# in the time series folder we save the data file. \n",
    "#in a compressed format as it has a lot of empty values\n",
    "np.savez_compressed(videos_out_timeseries + '\\\\allframedata.npz', keypoints_array=keypoints_array)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### That's it. \n",
    "\n",
    "Now go onto [Step 2 - Organising the data](Step2.OrganiseData.ipynb)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
