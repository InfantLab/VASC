{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Video Actor Synchroncy and Causality (VASC)\n",
    "## RAEng: Measuring Responsive Caregiving Project\n",
    "### Caspar Addyman, 2020\n",
    "### https://github.com/infantlab/VASC\n",
    "\n",
    "# Step 1  Process videos using OpenPose\n",
    "\n",
    "This script uses [OpenPose](https://github.com/CMU-Perceptual-Computing-Lab/openpose) human figure recognition neural network to create labeled wireframes for each figure in each frame of a video. It uses the [OpenPoseDemo](https://github.com/CMU-Perceptual-Computing-Lab/openpose/blob/master/doc/demo_overview.md) executable which must already be downloaded and installed.\n",
    "\n",
    "Additionally, you need to download the trained neural-network models that OpenPose uses. To do this go to the `models` subdirectory of OpenPose directory, and double-click / run the `models.bat` script.\n",
    "\n",
    "The `openposedemo` bin/exe file can be run manually from the command line.  \n",
    "\n",
    "OpenPoseDemo will go through a video frame by frame outputing a JSON file for each frame that contain\n",
    "s a set of coordinate points and for a wireframe for each"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#what python libraries to we need?\n",
    "import os\n",
    "import sys\n",
    "import time\n",
    "import glob\n",
    "import json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Where is OpenPose?\n",
    "\n",
    "We need the full path to your openpose directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\cas\\openpose-1.5.0-binaries-win64-gpu-python-flir-3d_recommended\\bin\\OpenPoseDemo.exe\n"
     ]
    }
   ],
   "source": [
    "# location of openposedemo - THIS WILL BE DIFFERENT ON YOUR COMPUTER\n",
    "openposepath = \"C:\\\\Users\\\\cas\\\\openpose-1.5.0-binaries-win64-gpu-python-flir-3d_recommended\\\\\"\n",
    "\n",
    "if sys.platform == \"win32\":\n",
    "    app = \"bin\\\\OpenPoseDemo.exe\"\n",
    "else:\n",
    "    app = 'bin\\\\OpenPoseDemo.bin'\n",
    "\n",
    "openposeapp = openposepath + app\n",
    "print(openposeapp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Where are your videos?\n",
    "\n",
    "In the next cell you need to specify the folder with your set of video files. So that we process them. These scripts use the following director structure. It expects your videos to be in a subfolder of your project \n",
    "\n",
    "```\n",
    "path\\to\\project\\myvideos\n",
    "```\n",
    "\n",
    "and then it creates a folder `out` in the project at the same level as the videos with three subfolders for JSON files, the aggregated timeseries and the analyses\n",
    "\n",
    "```\n",
    "path\\to\\project\\out\\openpose\n",
    "path\\to\\project\\out\\timeseries\n",
    "path\\to\\project\\out\\analyses\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\cas\\OneDrive - Goldsmiths College\\Projects\\Measuring Responsive Caregiving\\VASC\\..\\lookit\\\n",
      "C:\\Users\\cas\\OneDrive - Goldsmiths College\\Projects\\Measuring Responsive Caregiving\\VASC\\..\\lookit\\\\out\\openpose\n",
      "C:\\Users\\cas\\OneDrive - Goldsmiths College\\Projects\\Measuring Responsive Caregiving\\VASC\\..\\lookit\\\\out\\timeseries\n",
      "C:\\Users\\cas\\OneDrive - Goldsmiths College\\Projects\\Measuring Responsive Caregiving\\VASC\\..\\lookit\\\\out\\analyses\n"
     ]
    }
   ],
   "source": [
    "# where's the project folder? (with trailing slash)\n",
    "projectpath = os.getcwd() + \"\\\\..\\\\lookit\\\\\"\n",
    "\n",
    "# locations of videos and output\n",
    "videos_in = projectpath \n",
    "videos_out_openpose   = projectpath + \"out\\\\openpose\"\n",
    "videos_out_timeseries = projectpath + \"out\\\\timeseries\"\n",
    "videos_out_analyses   = projectpath + \"out\\\\analyses\"\n",
    "\n",
    "print(videos_in)\n",
    "print(videos_out_openpose)\n",
    "print(videos_out_timeseries)\n",
    "print(videos_out_analyses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "avis 0\n",
      "mp4s 10\n"
     ]
    }
   ],
   "source": [
    "#first get list of videos in the inbox\n",
    "avis = glob.glob(videos_in + \"*.avi\")\n",
    "mp4s = glob.glob(videos_in + \"*.mp4\")\n",
    "\n",
    "print(\"avis\" , len(avis))\n",
    "print(\"mp4s\" , len(mp4s))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n"
     ]
    }
   ],
   "source": [
    "#For the moment we will manually specify what videos to process. \n",
    "#TODO generate a list of force or skip videos to automate things slightly\n",
    "allvideos = []\n",
    "allvideos.extend(avis)\n",
    "allvideos.extend(mp4s)\n",
    "print(len(allvideos))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Calling the OpenPose app\n",
    "To operate OpenPose we pass a set of parameters to the demo executable. For the full list of options see  [OpenPoseDemo](https://github.com/CMU-Perceptual-Computing-Lab/openpose/blob/master/doc/demo_overview.md)\n",
    "\n",
    "Our main parameters are\n",
    "\n",
    "```\n",
    "--video        path\\to\\video_to_process   #input video\n",
    "--write_json   path\\to\\output_directory   #one json file per frame\n",
    "--write_video  path\\to\\output_directory   #video with identified figures\n",
    "--write_images path\\to\\output_directory   #one image per frame with wireframes\n",
    "--disable_blending true/false             # wireframes on black background (true) or blended on top of video (false)\n",
    " ```\n",
    "\n",
    "Other useful params\n",
    " ```\n",
    "--frame_first  100    #start from frame 100\n",
    "--display 0           #don't show the images as they are processed\n",
    " ```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = dict()\n",
    "params[\"write_json\"] = videos_out_openpose\n",
    "params[\"write_images\"] = videos_out_openpose  #for the moment dump images in output file - TODO name subfolder\n",
    "params[\"disable_blending\"] = \"true\"\n",
    "params[\"display\"]  = \"1\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The main openpose loop\n",
    "\n",
    "Call the openpose app for each of the videos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " --write_json \"C:\\Users\\cas\\OneDrive - Goldsmiths College\\Projects\\Measuring Responsive Caregiving\\VASC\\..\\lookit\\\\out\\openpose\" --write_images \"C:\\Users\\cas\\OneDrive - Goldsmiths College\\Projects\\Measuring Responsive Caregiving\\VASC\\..\\lookit\\\\out\\openpose\" --disable_blending \"true\" --display \"1\"\n",
      "\n",
      "\n",
      "Staring openpose processing of C:\\Users\\cas\\OneDrive - Goldsmiths College\\Projects\\Measuring Responsive Caregiving\\VASC\\..\\lookit\\lookit.01.mp4\n",
      "C:\\Users\\cas\\openpose-1.5.0-binaries-win64-gpu-python-flir-3d_recommended\\bin\\OpenPoseDemo.exe --video \"C:\\Users\\cas\\OneDrive - Goldsmiths College\\Projects\\Measuring Responsive Caregiving\\VASC\\..\\lookit\\lookit.01.mp4\" --write_video \"C:\\Users\\cas\\OneDrive - Goldsmiths College\\Projects\\Measuring Responsive Caregiving\\VASC\\..\\lookit\\\\out\\openpose\\lookit.01_output.avi\" --write_json \"C:\\Users\\cas\\OneDrive - Goldsmiths College\\Projects\\Measuring Responsive Caregiving\\VASC\\..\\lookit\\\\out\\openpose\" --write_images \"C:\\Users\\cas\\OneDrive - Goldsmiths College\\Projects\\Measuring Responsive Caregiving\\VASC\\..\\lookit\\\\out\\openpose\" --disable_blending \"true\" --display \"1\"\n",
      "Done C:\\Users\\cas\\OneDrive - Goldsmiths College\\Projects\\Measuring Responsive Caregiving\\VASC\\..\\lookit\\lookit.01.mp4\n",
      "It took 13 seconds for conversion.\n",
      "\n",
      "\n",
      "Staring openpose processing of C:\\Users\\cas\\OneDrive - Goldsmiths College\\Projects\\Measuring Responsive Caregiving\\VASC\\..\\lookit\\lookit.02.mp4\n",
      "C:\\Users\\cas\\openpose-1.5.0-binaries-win64-gpu-python-flir-3d_recommended\\bin\\OpenPoseDemo.exe --video \"C:\\Users\\cas\\OneDrive - Goldsmiths College\\Projects\\Measuring Responsive Caregiving\\VASC\\..\\lookit\\lookit.02.mp4\" --write_video \"C:\\Users\\cas\\OneDrive - Goldsmiths College\\Projects\\Measuring Responsive Caregiving\\VASC\\..\\lookit\\\\out\\openpose\\lookit.02_output.avi\" --write_json \"C:\\Users\\cas\\OneDrive - Goldsmiths College\\Projects\\Measuring Responsive Caregiving\\VASC\\..\\lookit\\\\out\\openpose\" --write_images \"C:\\Users\\cas\\OneDrive - Goldsmiths College\\Projects\\Measuring Responsive Caregiving\\VASC\\..\\lookit\\\\out\\openpose\" --disable_blending \"true\" --display \"1\"\n",
      "Done C:\\Users\\cas\\OneDrive - Goldsmiths College\\Projects\\Measuring Responsive Caregiving\\VASC\\..\\lookit\\lookit.02.mp4\n",
      "It took 13 seconds for conversion.\n",
      "\n",
      "\n",
      "Staring openpose processing of C:\\Users\\cas\\OneDrive - Goldsmiths College\\Projects\\Measuring Responsive Caregiving\\VASC\\..\\lookit\\lookit.03.mp4\n",
      "C:\\Users\\cas\\openpose-1.5.0-binaries-win64-gpu-python-flir-3d_recommended\\bin\\OpenPoseDemo.exe --video \"C:\\Users\\cas\\OneDrive - Goldsmiths College\\Projects\\Measuring Responsive Caregiving\\VASC\\..\\lookit\\lookit.03.mp4\" --write_video \"C:\\Users\\cas\\OneDrive - Goldsmiths College\\Projects\\Measuring Responsive Caregiving\\VASC\\..\\lookit\\\\out\\openpose\\lookit.03_output.avi\" --write_json \"C:\\Users\\cas\\OneDrive - Goldsmiths College\\Projects\\Measuring Responsive Caregiving\\VASC\\..\\lookit\\\\out\\openpose\" --write_images \"C:\\Users\\cas\\OneDrive - Goldsmiths College\\Projects\\Measuring Responsive Caregiving\\VASC\\..\\lookit\\\\out\\openpose\" --disable_blending \"true\" --display \"1\"\n",
      "Done C:\\Users\\cas\\OneDrive - Goldsmiths College\\Projects\\Measuring Responsive Caregiving\\VASC\\..\\lookit\\lookit.03.mp4\n",
      "It took 12 seconds for conversion.\n",
      "\n",
      "\n",
      "Staring openpose processing of C:\\Users\\cas\\OneDrive - Goldsmiths College\\Projects\\Measuring Responsive Caregiving\\VASC\\..\\lookit\\lookit.04.mp4\n",
      "C:\\Users\\cas\\openpose-1.5.0-binaries-win64-gpu-python-flir-3d_recommended\\bin\\OpenPoseDemo.exe --video \"C:\\Users\\cas\\OneDrive - Goldsmiths College\\Projects\\Measuring Responsive Caregiving\\VASC\\..\\lookit\\lookit.04.mp4\" --write_video \"C:\\Users\\cas\\OneDrive - Goldsmiths College\\Projects\\Measuring Responsive Caregiving\\VASC\\..\\lookit\\\\out\\openpose\\lookit.04_output.avi\" --write_json \"C:\\Users\\cas\\OneDrive - Goldsmiths College\\Projects\\Measuring Responsive Caregiving\\VASC\\..\\lookit\\\\out\\openpose\" --write_images \"C:\\Users\\cas\\OneDrive - Goldsmiths College\\Projects\\Measuring Responsive Caregiving\\VASC\\..\\lookit\\\\out\\openpose\" --disable_blending \"true\" --display \"1\"\n",
      "Done C:\\Users\\cas\\OneDrive - Goldsmiths College\\Projects\\Measuring Responsive Caregiving\\VASC\\..\\lookit\\lookit.04.mp4\n",
      "It took 24 seconds for conversion.\n",
      "\n",
      "\n",
      "Staring openpose processing of C:\\Users\\cas\\OneDrive - Goldsmiths College\\Projects\\Measuring Responsive Caregiving\\VASC\\..\\lookit\\lookit.05.mp4\n",
      "C:\\Users\\cas\\openpose-1.5.0-binaries-win64-gpu-python-flir-3d_recommended\\bin\\OpenPoseDemo.exe --video \"C:\\Users\\cas\\OneDrive - Goldsmiths College\\Projects\\Measuring Responsive Caregiving\\VASC\\..\\lookit\\lookit.05.mp4\" --write_video \"C:\\Users\\cas\\OneDrive - Goldsmiths College\\Projects\\Measuring Responsive Caregiving\\VASC\\..\\lookit\\\\out\\openpose\\lookit.05_output.avi\" --write_json \"C:\\Users\\cas\\OneDrive - Goldsmiths College\\Projects\\Measuring Responsive Caregiving\\VASC\\..\\lookit\\\\out\\openpose\" --write_images \"C:\\Users\\cas\\OneDrive - Goldsmiths College\\Projects\\Measuring Responsive Caregiving\\VASC\\..\\lookit\\\\out\\openpose\" --disable_blending \"true\" --display \"1\"\n",
      "Done C:\\Users\\cas\\OneDrive - Goldsmiths College\\Projects\\Measuring Responsive Caregiving\\VASC\\..\\lookit\\lookit.05.mp4\n",
      "It took 26 seconds for conversion.\n",
      "\n",
      "\n",
      "Staring openpose processing of C:\\Users\\cas\\OneDrive - Goldsmiths College\\Projects\\Measuring Responsive Caregiving\\VASC\\..\\lookit\\lookit.06.mp4\n",
      "C:\\Users\\cas\\openpose-1.5.0-binaries-win64-gpu-python-flir-3d_recommended\\bin\\OpenPoseDemo.exe --video \"C:\\Users\\cas\\OneDrive - Goldsmiths College\\Projects\\Measuring Responsive Caregiving\\VASC\\..\\lookit\\lookit.06.mp4\" --write_video \"C:\\Users\\cas\\OneDrive - Goldsmiths College\\Projects\\Measuring Responsive Caregiving\\VASC\\..\\lookit\\\\out\\openpose\\lookit.06_output.avi\" --write_json \"C:\\Users\\cas\\OneDrive - Goldsmiths College\\Projects\\Measuring Responsive Caregiving\\VASC\\..\\lookit\\\\out\\openpose\" --write_images \"C:\\Users\\cas\\OneDrive - Goldsmiths College\\Projects\\Measuring Responsive Caregiving\\VASC\\..\\lookit\\\\out\\openpose\" --disable_blending \"true\" --display \"1\"\n",
      "Done C:\\Users\\cas\\OneDrive - Goldsmiths College\\Projects\\Measuring Responsive Caregiving\\VASC\\..\\lookit\\lookit.06.mp4\n",
      "It took 16 seconds for conversion.\n",
      "\n",
      "\n",
      "Staring openpose processing of C:\\Users\\cas\\OneDrive - Goldsmiths College\\Projects\\Measuring Responsive Caregiving\\VASC\\..\\lookit\\lookit.07.mp4\n",
      "C:\\Users\\cas\\openpose-1.5.0-binaries-win64-gpu-python-flir-3d_recommended\\bin\\OpenPoseDemo.exe --video \"C:\\Users\\cas\\OneDrive - Goldsmiths College\\Projects\\Measuring Responsive Caregiving\\VASC\\..\\lookit\\lookit.07.mp4\" --write_video \"C:\\Users\\cas\\OneDrive - Goldsmiths College\\Projects\\Measuring Responsive Caregiving\\VASC\\..\\lookit\\\\out\\openpose\\lookit.07_output.avi\" --write_json \"C:\\Users\\cas\\OneDrive - Goldsmiths College\\Projects\\Measuring Responsive Caregiving\\VASC\\..\\lookit\\\\out\\openpose\" --write_images \"C:\\Users\\cas\\OneDrive - Goldsmiths College\\Projects\\Measuring Responsive Caregiving\\VASC\\..\\lookit\\\\out\\openpose\" --disable_blending \"true\" --display \"1\"\n",
      "Done C:\\Users\\cas\\OneDrive - Goldsmiths College\\Projects\\Measuring Responsive Caregiving\\VASC\\..\\lookit\\lookit.07.mp4\n",
      "It took 19 seconds for conversion.\n",
      "\n",
      "\n",
      "Staring openpose processing of C:\\Users\\cas\\OneDrive - Goldsmiths College\\Projects\\Measuring Responsive Caregiving\\VASC\\..\\lookit\\lookit.08.mp4\n",
      "C:\\Users\\cas\\openpose-1.5.0-binaries-win64-gpu-python-flir-3d_recommended\\bin\\OpenPoseDemo.exe --video \"C:\\Users\\cas\\OneDrive - Goldsmiths College\\Projects\\Measuring Responsive Caregiving\\VASC\\..\\lookit\\lookit.08.mp4\" --write_video \"C:\\Users\\cas\\OneDrive - Goldsmiths College\\Projects\\Measuring Responsive Caregiving\\VASC\\..\\lookit\\\\out\\openpose\\lookit.08_output.avi\" --write_json \"C:\\Users\\cas\\OneDrive - Goldsmiths College\\Projects\\Measuring Responsive Caregiving\\VASC\\..\\lookit\\\\out\\openpose\" --write_images \"C:\\Users\\cas\\OneDrive - Goldsmiths College\\Projects\\Measuring Responsive Caregiving\\VASC\\..\\lookit\\\\out\\openpose\" --disable_blending \"true\" --display \"1\"\n",
      "Done C:\\Users\\cas\\OneDrive - Goldsmiths College\\Projects\\Measuring Responsive Caregiving\\VASC\\..\\lookit\\lookit.08.mp4\n",
      "It took 16 seconds for conversion.\n",
      "\n",
      "\n",
      "Staring openpose processing of C:\\Users\\cas\\OneDrive - Goldsmiths College\\Projects\\Measuring Responsive Caregiving\\VASC\\..\\lookit\\lookit.09.mp4\n",
      "C:\\Users\\cas\\openpose-1.5.0-binaries-win64-gpu-python-flir-3d_recommended\\bin\\OpenPoseDemo.exe --video \"C:\\Users\\cas\\OneDrive - Goldsmiths College\\Projects\\Measuring Responsive Caregiving\\VASC\\..\\lookit\\lookit.09.mp4\" --write_video \"C:\\Users\\cas\\OneDrive - Goldsmiths College\\Projects\\Measuring Responsive Caregiving\\VASC\\..\\lookit\\\\out\\openpose\\lookit.09_output.avi\" --write_json \"C:\\Users\\cas\\OneDrive - Goldsmiths College\\Projects\\Measuring Responsive Caregiving\\VASC\\..\\lookit\\\\out\\openpose\" --write_images \"C:\\Users\\cas\\OneDrive - Goldsmiths College\\Projects\\Measuring Responsive Caregiving\\VASC\\..\\lookit\\\\out\\openpose\" --disable_blending \"true\" --display \"1\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done C:\\Users\\cas\\OneDrive - Goldsmiths College\\Projects\\Measuring Responsive Caregiving\\VASC\\..\\lookit\\lookit.09.mp4\n",
      "It took 17 seconds for conversion.\n",
      "\n",
      "\n",
      "Staring openpose processing of C:\\Users\\cas\\OneDrive - Goldsmiths College\\Projects\\Measuring Responsive Caregiving\\VASC\\..\\lookit\\lookit.10.mp4\n",
      "C:\\Users\\cas\\openpose-1.5.0-binaries-win64-gpu-python-flir-3d_recommended\\bin\\OpenPoseDemo.exe --video \"C:\\Users\\cas\\OneDrive - Goldsmiths College\\Projects\\Measuring Responsive Caregiving\\VASC\\..\\lookit\\lookit.10.mp4\" --write_video \"C:\\Users\\cas\\OneDrive - Goldsmiths College\\Projects\\Measuring Responsive Caregiving\\VASC\\..\\lookit\\\\out\\openpose\\lookit.10_output.avi\" --write_json \"C:\\Users\\cas\\OneDrive - Goldsmiths College\\Projects\\Measuring Responsive Caregiving\\VASC\\..\\lookit\\\\out\\openpose\" --write_images \"C:\\Users\\cas\\OneDrive - Goldsmiths College\\Projects\\Measuring Responsive Caregiving\\VASC\\..\\lookit\\\\out\\openpose\" --disable_blending \"true\" --display \"1\"\n",
      "Done C:\\Users\\cas\\OneDrive - Goldsmiths College\\Projects\\Measuring Responsive Caregiving\\VASC\\..\\lookit\\lookit.10.mp4\n",
      "It took 17 seconds for conversion.\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'json' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-7-290881e3852b>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     39\u001b[0m \u001b[1;31m#now we've finished, write a list of processed videos to a file\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     40\u001b[0m \u001b[1;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'processed.json'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'w'\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0moutfile\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 41\u001b[1;33m     \u001b[0mjson\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdump\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mprocessed\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moutfile\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     42\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     43\u001b[0m \u001b[1;31m#change the directory back\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'json' is not defined"
     ]
    }
   ],
   "source": [
    "jupwd =  os.getcwd() + \"\\\\\" #keep track of current directory so we can change back to it after processing\n",
    "\n",
    "optstring = \"\"\n",
    "for key in params:\n",
    "    optstring += \" --\" + key +  ' \"' + params[key] + '\"' #need to quote paths \n",
    "\n",
    "print(optstring)\n",
    "\n",
    "processed = []\n",
    "os.chdir(openposepath)\n",
    "for vid in allvideos:\n",
    "    #first we need base name of video for the output file name\n",
    "    base = os.path.basename(vid)\n",
    "    vidbasename = os.path.splitext(base)\n",
    "    video_outname = vidbasename[0] + \"_output.avi\"\n",
    "    try:\n",
    "        print(\"\\n\\nStaring openpose processing of \" + vid)\n",
    "        # Log the time\n",
    "        time_start = time.time()\n",
    "        video = ' --video \"' + vid + '\"'\n",
    "        video_out = ' --write_video \"' + videos_out_openpose + '\\\\' + video_outname + '\"'\n",
    "        opbin = openposeapp + video + video_out + optstring\n",
    "        print(opbin)\n",
    "        exitcode = os.system(opbin)\n",
    "        # Log the time again\n",
    "        time_end = time.time()\n",
    "        if (exitcode == 0):\n",
    "            # Print stats\n",
    "            processed.append(vidbasename[0])\n",
    "            print (\"Done \" + vid)\n",
    "            print (\"It took %d seconds for conversion.\" % (time_end-time_start))\n",
    "        else:\n",
    "            print(\"OpenPose error. Exit code %d\" % exitcode)\n",
    "    except Exception as e:\n",
    "        print(\"Error: \", e)\n",
    "        pass\n",
    "    \n",
    "#change the directory back\n",
    "os.chdir(jupwd)\n",
    "    \n",
    "#now we've finished, write a list of processed videos to a file\n",
    "with open(videos_out_openpose + '\\\\processed.json', 'w') as outfile:\n",
    "    json.dump(processed, outfile)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def video_to_frames(input_loc, output_loc):\n",
    "    \"\"\"Function to extract frames from input video file\n",
    "    and save them as separate frames in an output directory.\n",
    "    Args:\n",
    "        input_loc: Input video file.\n",
    "        output_loc: Output directory to save the frames.\n",
    "    Returns:\n",
    "        None\n",
    "    \"\"\"\n",
    "    try:\n",
    "        os.mkdir(output_loc)\n",
    "    except OSError:\n",
    "        pass\n",
    "    # Log the time\n",
    "    time_start = time.time()\n",
    "    # Start capturing the feed\n",
    "    cap = cv2.VideoCapture(input_loc)\n",
    "    # Find the number of frames\n",
    "    video_length = int(cap.get(cv2.CAP_PROP_FRAME_COUNT)) - 1\n",
    "    print (\"Number of frames: \", video_length)\n",
    "    count = 0\n",
    "    print (\"Converting video..\\n\")\n",
    "    # Start converting the video\n",
    "    while cap.isOpened():\n",
    "        # Extract the frame\n",
    "        ret, frame = cap.read()\n",
    "        # Write the results back to output location.\n",
    "        cv2.imwrite(output_loc + \"/%#05d.jpg\" % (count+1), frame)\n",
    "        count = count + 1\n",
    "        # If there are no more frames left\n",
    "        if (count > (video_length-1)):\n",
    "            # Log the time again\n",
    "            time_end = time.time()\n",
    "            # Release the feed\n",
    "            cap.release()\n",
    "            # Print stats\n",
    "            print (\"Done extracting frames.\\n%d frames extracted\" % count)\n",
    "            print (\"It took %d seconds for conversion.\" % (time_end-time_start))\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
