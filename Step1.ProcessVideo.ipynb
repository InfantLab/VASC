{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Video Actor Synchroncy and Causality (VASC)\n",
    "## RAEng: Measuring Responsive Caregiving Project\n",
    "### Caspar Addyman, 2020\n",
    "### https://github.com/infantlab/VASC\n",
    "\n",
    "# Step 1  Process videos using OpenPose\n",
    "\n",
    "This script uses [OpenPose](https://github.com/CMU-Perceptual-Computing-Lab/openpose) human figure recognition neural network to create labeled wireframes for each figure in each frame of a video. OpenPoseDemo will go through a video frame by frame outputing a JSON file for each frame that contains a set of coordinate points and for a wireframe for each video.\n",
    "\n",
    "#### Before running\n",
    "First we need to download and install the [OpenPoseDemo](https://github.com/CMU-Perceptual-Computing-Lab/openpose/blob/master/doc/demo_overview.md) executable.\n",
    "\n",
    "Additionally, you need to download the trained neural-network models that OpenPose uses. To do this go to the `models` subdirectory of OpenPose directory, and double-click / run the `models.bat` script.\n",
    "\n",
    "The `openposedemo` bin/exe file can be run manually from the command line. It is worth trying this first so you understand what  `openposedemo` is. See [this guide](https://github.com/CMU-Perceptual-Computing-Lab/openpose/blob/master/doc/demo_overview.md) or open a terminal app or Windows Powershell, navigate to the openpose installation folder and then try this command\n",
    "\n",
    "```\n",
    ":: Windows\n",
    "bin\\OpenPoseDemo.exe --video examples\\media\\video.avi --write_json output\n",
    "# Mac/Linux\n",
    "./build/examples/openpose/openpose.bin --video examples/media/video.avi --write_json output\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load python libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#what python libraries to we need?\n",
    "import os\n",
    "import sys\n",
    "import time\n",
    "import glob\n",
    "import json\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Where is OpenPose?\n",
    "\n",
    "We need the full path to your openpose directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# location of openposedemo - THIS WILL BE DIFFERENT ON YOUR COMPUTER\n",
    "openposepath = \"C:\\\\Users\\\\cas\\\\openpose-1.5.0-binaries-win64-gpu-python-flir-3d_recommended\\\\\"\n",
    "#openposepath = \"C:\\\\Users\\\\caspar\\\\openpose-1.4.0-win64-cpu-binaries\\\\\"\n",
    "\n",
    "if sys.platform == \"win32\":\n",
    "    app = \"bin\\\\OpenPoseDemo.exe\"\n",
    "else:\n",
    "    app = 'bin\\\\OpenPoseDemo.bin'\n",
    "\n",
    "openposeapp = openposepath + app\n",
    "print(openposeapp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Where are your videos?\n",
    "\n",
    "In the next cell you need to specify the folder with your set of video files. So that we process them. These scripts use the following director structure. It expects your videos to be in a subfolder of your project \n",
    "\n",
    "```\n",
    "path\\to\\project\\myvideos\n",
    "```\n",
    "\n",
    "and then it creates a folder `out` in the project at the same level as the videos with three subfolders for JSON files, the aggregated timeseries and the analyses\n",
    "\n",
    "```\n",
    "path\\to\\project\\out\\openpose\n",
    "path\\to\\project\\out\\timeseries\n",
    "path\\to\\project\\out\\analyses\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# where's the project folder? (with trailing slash)\n",
    "# projectpath = os.getcwd() + \"\\\\..\\\\lookit\\\\\"\n",
    "projectpath = \"C:\\\\Users\\\\Cas\\\\OneDrive - Goldsmiths College\\\\Projects\\\\Measuring Responsive Caregiving\\\\lookit\\\\\"\n",
    "\n",
    "# locations of videos and output\n",
    "videos_in = projectpath \n",
    "videos_out_openpose   = projectpath + \"out\\\\openpose\"\n",
    "videos_out_timeseries = projectpath + \"out\\\\timeseries\"\n",
    "videos_out_analyses   = projectpath + \"out\\\\analyses\"\n",
    "\n",
    "print(videos_in)\n",
    "print(videos_out_openpose)\n",
    "print(videos_out_timeseries)\n",
    "print(videos_out_analyses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#first get list of videos in the inbox\n",
    "avis = glob.glob(videos_in + \"*.avi\")\n",
    "mp4s = glob.glob(videos_in + \"*.mp4\")\n",
    "\n",
    "print(\"We found %d avis\" % len(avis))\n",
    "print(\"We found %d mp4s\" % len(mp4s))\n",
    "\n",
    "#For the moment we will manually specify what videos to process. \n",
    "#TODO generate a list of force or skip videos to automate things slightly\n",
    "allvideos = []\n",
    "allvideos.extend(avis)\n",
    "allvideos.extend(mp4s)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Calling the OpenPose app\n",
    "To operate OpenPose we pass a set of parameters to the demo executable. For the full list of options see  [OpenPoseDemo](https://github.com/CMU-Perceptual-Computing-Lab/openpose/blob/master/doc/demo_overview.md)\n",
    "\n",
    "Our main parameters are\n",
    "\n",
    "```\n",
    "--video        path\\to\\video_to_process   #input video\n",
    "--write_json   path\\to\\output_directory   #one json file per frame\n",
    "--write_video  path\\to\\output_directory   #video with identified figures\n",
    "--write_images path\\to\\output_directory   #one image per frame with wireframes\n",
    "--disable_blending true/false             # wireframes on black background (true) or blended on top of video (false)\n",
    " ```\n",
    "\n",
    "Other useful params\n",
    " ```\n",
    "--frame_first  100    #start from frame 100\n",
    "--display 0           #don't show the images as they are processed\n",
    " ```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = dict()\n",
    "params[\"write_json\"] = videos_out_openpose\n",
    "params[\"write_images\"] = videos_out_openpose  #for the moment dump images in output file - TODO name subfolder\n",
    "params[\"disable_blending\"] = \"true\"\n",
    "params[\"display\"]  = \"1\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The main openpose loop\n",
    "\n",
    "Call the openpose app for each of the videos at a time. For each one print the full command that we use so that you can use it manually to investigate any errors. \n",
    "\n",
    "Finally, we write a simple list of the processed videos to a file called `videos.json`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "currdir =  os.getcwd() + \"\\\\\" #keep track of current directory so we can change back to it after processing\n",
    "\n",
    "optstring = \"\"\n",
    "for key in params:\n",
    "    optstring += \" --\" + key +  ' \"' + params[key] + '\"' #need to quote paths \n",
    "\n",
    "print(optstring)\n",
    "\n",
    "videosjson = {}\n",
    "os.chdir(openposepath)\n",
    "for vid in allvideos:\n",
    "    #first we need base name of video for the output file name\n",
    "    fullname = os.path.basename(vid)\n",
    "    base, fmt = os.path.splitext(fullname)\n",
    "    video_outname = base + \"_output.avi\"\n",
    "    #log some info about this video\n",
    "    videosjson[base] = {}\n",
    "    videosjson[base][\"fullname\"] = fullname\n",
    "    videosjson[base][\"format\"] = fmt\n",
    "    videosjson[base][\"openpose\"] =  {\"exitcode\" : None, \"when\" : None} \n",
    "\n",
    "    print(\"\\n\\nStaring openpose processing of \" + vid)\n",
    "    try:\n",
    "        # Log the time\n",
    "        time_start = time.time()\n",
    "        video = ' --video \"' + vid + '\"'\n",
    "        video_out = ' --write_video \"' + videos_out_openpose + '\\\\' + video_outname + '\"'\n",
    "        opbin = openposeapp + video + video_out + optstring\n",
    "        print(opbin)\n",
    "        exitcode = os.system(opbin)\n",
    "        videosjson[base][\"openpose\"][\"exitcode\"] = exitcode\n",
    "        # Log the time again\n",
    "        time_end = time.time()\n",
    "        if (exitcode == 0):\n",
    "            videosjson[base][\"openpose\"][\"when\"] = datetime.now().isoformat()\n",
    "            videosjson[base][\"openpose\"][\"out\"] = videos_out_openpose + '\\\\' + video_outname\n",
    "            print (\"Done \" + vid)\n",
    "            print (\"It took %d seconds for conversion.\" % (time_end-time_start))\n",
    "        else:\n",
    "            print(\"OpenPose error. Exit code %d\" % exitcode)\n",
    "    except Exception as e:\n",
    "        print(\"Error: \", e)\n",
    "        pass\n",
    "    \n",
    "#change the directory back\n",
    "os.chdir(currdir)\n",
    "    \n",
    "#now we've finished, write a list of processed videos to a file\n",
    "with open(videos_out_openpose + '\\\\videos.json', 'w') as outfile:\n",
    "    json.dump(videosjson, outfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
