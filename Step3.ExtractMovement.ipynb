{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Video Actor Synchroncy and Causality (VASC)\n",
    "## RAEng: Measuring Responsive Caregiving Project\n",
    "### Caspar Addyman, 2020\n",
    "### https://github.com/infantlab/VASC\n",
    "\n",
    "# Step 3: Analyse the data using scipy statsmodels\n",
    "\n",
    "This script correlates and compares the timeseries of wireframes for the two figures in the video `[\"parent\", \"infant\"]`\n",
    "\n",
    "We start by reloading the saved parquet file containing the multi-index numpy array of all [OpenPose](https://github.com/CMU-Perceptual-Computing-Lab/openpose) data from all pairs of individuals.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Automatic pdb calling has been turned ON\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "import json\n",
    "import math\n",
    "import scipy.fft\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pyarrow.parquet as pq\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import logging\n",
    "import ipywidgets as widgets  #let's us add buttons and sliders to this page.\n",
    "from ipycanvas import Canvas\n",
    "\n",
    "import vasc #a module of our own functions (found in vasc.py in this folder)\n",
    "\n",
    "#turn on debugging\n",
    "logger = logging.getLogger()\n",
    "logger.setLevel(logging.INFO)\n",
    "%pdb on"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1 Settings?\n",
    "\n",
    "Load a json file that tells us where to find our videos and where to save the data. You should create a different settings file for each project. Then you don't need to change any other values in the script for Step 1 or Step 2.\n",
    "\n",
    "TODO - write a helper to create a settings file\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Existing settings.json found..\n"
     ]
    }
   ],
   "source": [
    "settingsjson = \".\\\\DrumTutorial\\\\Drum.Tutorial.settings.json\"\n",
    "\n",
    "try:\n",
    "    with open(settingsjson) as json_file:\n",
    "        settings = json.load(json_file)\n",
    "        print(\"Existing settings.json found..\")\n",
    "except json.JSONDecodeError:\n",
    "    logging.exception(\"Settings file was not valid JSON. (You might be missing a comma or a bracket.)\")\n",
    "except Exception as e:\n",
    "        emsg = str(e)\n",
    "        #show the error\n",
    "        print(\"Error: \",emsg)\n",
    "        print(\"No setting.json file found!\\nPlease see Step 0 for instructions\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "anon: False\n",
      "includeHands: True\n"
     ]
    }
   ],
   "source": [
    "anon = settings[\"flags\"][\"anon\"]\n",
    "print(f\"anon: {anon}\")\n",
    "includeHands = settings[\"flags\"][\"includeHands\"]\n",
    "print(f\"includeHands: {includeHands}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "videos_in:  .\\DrumTutorial\\videos\n",
      "videos_out:  .\\DrumTutorial\\\n",
      "videos_out_openpose:  .\\DrumTutorial\\openpose\n",
      "videos_out_timeseries:  .\\DrumTutorial\\timeseries\n",
      "videos_out_analyses:  .\\DrumTutorial\\analyses\n"
     ]
    }
   ],
   "source": [
    "# where's the project data folder? (with trailing slash)\n",
    "projectpath = settings[\"paths\"][\"project\"]\n",
    "#where are your video files?\n",
    "videos_in = settings[\"paths\"][\"videos_in\"]\n",
    "\n",
    "# locations of videos and output\n",
    "videos_out = settings[\"paths\"][\"videos_out\"]\n",
    "videos_out_openpose   = settings[\"paths\"][\"videos_out_openpose\"]\n",
    "videos_out_timeseries = settings[\"paths\"][\"videos_out_timeseries\"]\n",
    "videos_out_analyses   = settings[\"paths\"][\"videos_out_analyses\"]\n",
    "\n",
    "print(\"videos_in: \", videos_in)\n",
    "print(\"videos_out: \", videos_out)\n",
    "print(\"videos_out_openpose: \", videos_out_openpose)\n",
    "print(\"videos_out_timeseries: \", videos_out_timeseries)\n",
    "print(\"videos_out_analyses: \", videos_out_analyses)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 Load the clean data as a DataFrame\n",
    "\n",
    "Reload the clean data file created in step 2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Existing clean.json found..\n"
     ]
    }
   ],
   "source": [
    "#retrieve the list of base names of processed videos.\n",
    "videosjson = settings[\"paths\"][\"videos_out\"] + '\\\\' + settings[\"filenames\"][\"clean_json\"]\n",
    "try:\n",
    "    with open(videosjson) as json_file:\n",
    "        videos = json.load(json_file)\n",
    "        print(\"Existing clean.json found..\")\n",
    "except:\n",
    "    videos = {}\n",
    "    print(\"No clean.json file found, please locate the file or complete Step 2 first.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reading parquet file(s):\n",
      "video  1fa339b_04-test-trials                                                 \\\n",
      "person                 infant                                                  \n",
      "coord                      0        1         2        3        4         5    \n",
      "0                     603.999  402.094  0.812414  619.638  488.323  0.591055   \n",
      "1                     605.907  400.237  0.817730  619.558  490.241  0.580483   \n",
      "2                     607.815  400.268  0.798972  621.568  490.254  0.570408   \n",
      "3                     605.932  402.122  0.807359  617.672  484.432  0.616228   \n",
      "4                     605.928  402.124  0.807981  617.688  482.488  0.613706   \n",
      "\n",
      "video                                        ... b22644a_14-test-trials       \\\n",
      "person                                       ...                 parent        \n",
      "coord        6        7         8        9   ...                     65   66   \n",
      "0       478.519  484.430  0.513021  374.709  ...                    0.0  0.0   \n",
      "1       476.577  488.301  0.516335  372.761  ...                    0.0  0.0   \n",
      "2       478.491  486.372  0.500429  376.642  ...                    0.0  0.0   \n",
      "3       476.522  484.420  0.517500  380.506  ...                    0.0  0.0   \n",
      "4       476.541  482.474  0.516069  380.512  ...                    0.0  0.0   \n",
      "\n",
      "video                                           \n",
      "person                                          \n",
      "coord    67   68   69   70   71   72   73   74  \n",
      "0       0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
      "1       0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
      "2       0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
      "3       0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
      "4       0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
      "\n",
      "[5 rows x 4500 columns]\n"
     ]
    }
   ],
   "source": [
    "print('reading parquet file(s):')\n",
    "df = pq.read_table(videos_out_timeseries + '\\\\' + settings[\"filenames\"][\"cleandataparquet\"]).to_pandas()\n",
    "\n",
    "#sort the column names as this helps with indexing\n",
    "df = df.sort_index(axis = 1)\n",
    "\n",
    "if includeHands:\n",
    "    lh = pq.read_table(videos_out_timeseries + '\\\\' + settings[\"filenames\"][\"lefthandparquet\"]).to_pandas()\n",
    "    rh = pq.read_table(videos_out_timeseries + '\\\\' + settings[\"filenames\"][\"righthandparquet\"]).to_pandas()\n",
    "    lh = lh.sort_index(axis = 1)\n",
    "    rh = rh.sort_index(axis = 1)\n",
    "    \n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.2 Process the data\n",
    "\n",
    "Before focusing directly on the body part of interest there are several global processing steps we can apply to all the data that we have.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2.1 Interpolate missing data.\n",
    "\n",
    "In the dataframe all missing data is represented by a zerro (0.0) value. This is where a body part is not visible or goes off the edge of the frame. We'd like to interpolate these gaps (if possible). So first we find and replace all zeros with `np.nan` (numpy's indcitor for 'not a number'.\n",
    "\n",
    "Then we use the `interpolate()` method to linearly interpolate the missing data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.replace(0.0, np.nan)\n",
    "if includeHands:\n",
    "    rh = rh.replace(0.0, np.nan)\n",
    "    lh = lh.replace(0.0, np.nan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#are we going to use all the data or a subset?\n",
    "first = 0\n",
    "last = df.shape[0]\n",
    "\n",
    "df = df.truncate(before  = first, after = last)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#linear interpolate missing values\n",
    "df = df.interpolate()\n",
    "#may still have some NaNs at start so back fill these with first non-zero value\n",
    "#eg  [NaN, NaN, 3.1, 3.2, ...] -> [3.1, 3.1, 3.1, 3.2, ...]\n",
    "df = df.fillna(method = 'backfill')\n",
    "\n",
    "if includeHands:\n",
    "    rh = rh.interpolate()\n",
    "    rh = rh.fillna(method = 'backfill')\n",
    "    lh = lh.interpolate()\n",
    "    lh = lh.fillna(method = 'backfill')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "video  1fa339b_04-test-trials                                                 \\\n",
      "person                 infant                                                  \n",
      "coord                      0        1         2        3        4         5    \n",
      "0                     603.999  402.094  0.812414  619.638  488.323  0.591055   \n",
      "1                     605.907  400.237  0.817730  619.558  490.241  0.580483   \n",
      "2                     607.815  400.268  0.798972  621.568  490.254  0.570408   \n",
      "3                     605.932  402.122  0.807359  617.672  484.432  0.616228   \n",
      "4                     605.928  402.124  0.807981  617.688  482.488  0.613706   \n",
      "\n",
      "video                                        ... b22644a_14-test-trials      \\\n",
      "person                                       ...                 parent       \n",
      "coord        6        7         8        9   ...                     65  66   \n",
      "0       478.519  484.430  0.513021  374.709  ...                    NaN NaN   \n",
      "1       476.577  488.301  0.516335  372.761  ...                    NaN NaN   \n",
      "2       478.491  486.372  0.500429  376.642  ...                    NaN NaN   \n",
      "3       476.522  484.420  0.517500  380.506  ...                    NaN NaN   \n",
      "4       476.541  482.474  0.516069  380.512  ...                    NaN NaN   \n",
      "\n",
      "video                                   \n",
      "person                                  \n",
      "coord   67  68  69  70  71  72  73  74  \n",
      "0      NaN NaN NaN NaN NaN NaN NaN NaN  \n",
      "1      NaN NaN NaN NaN NaN NaN NaN NaN  \n",
      "2      NaN NaN NaN NaN NaN NaN NaN NaN  \n",
      "3      NaN NaN NaN NaN NaN NaN NaN NaN  \n",
      "4      NaN NaN NaN NaN NaN NaN NaN NaN  \n",
      "\n",
      "[5 rows x 4500 columns]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(956, 4500)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#take a quick look\n",
    "print(df.head())\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "video  1fa339b_04-test-trials                                                \\\n",
      "person                 infant                                                 \n",
      "coord                      0        1         2        3       4         5    \n",
      "0                     674.631  568.637  0.406643  678.243  531.79  0.410103   \n",
      "1                     674.631  568.637  0.406643  678.243  531.79  0.410103   \n",
      "2                     674.631  568.637  0.406643  678.243  531.79  0.410103   \n",
      "3                     674.631  568.637  0.406643  678.243  531.79  0.410103   \n",
      "4                     674.631  568.637  0.406643  678.243  531.79  0.410103   \n",
      "\n",
      "video                                        ... b22644a_14-test-trials  \\\n",
      "person                                       ...                 parent   \n",
      "coord        6        7         8        9   ...                     53   \n",
      "0       671.741  497.833  0.225364  634.171  ...               0.517503   \n",
      "1       671.741  497.833  0.225364  634.171  ...               0.446704   \n",
      "2       671.741  497.833  0.225364  634.171  ...               0.491572   \n",
      "3       671.741  497.833  0.225364  634.171  ...               0.543662   \n",
      "4       671.741  497.833  0.225364  634.171  ...               0.513971   \n",
      "\n",
      "video                                                                    \\\n",
      "person                                                                    \n",
      "coord        54       55        56       57       58        59       60   \n",
      "0       745.277  701.826  0.417300  733.839  726.228  0.392195  726.213   \n",
      "1       749.063  691.670  0.455888  738.387  716.836  0.516761  731.523   \n",
      "2       747.194  695.258  0.511633  736.371  719.997  0.479978  730.186   \n",
      "3       747.320  694.589  0.486521  737.079  718.222  0.536118  729.990   \n",
      "4       745.524  695.798  0.415926  739.260  714.590  0.360363  716.553   \n",
      "\n",
      "video                      \n",
      "person                     \n",
      "coord        61        62  \n",
      "0       740.717  0.141105  \n",
      "1       737.426  0.272352  \n",
      "2       739.325  0.269139  \n",
      "3       739.491  0.264435  \n",
      "4       741.212  0.099560  \n",
      "\n",
      "[5 rows x 3780 columns]\n"
     ]
    }
   ],
   "source": [
    "print(lh.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2.2 Mean body part movements\n",
    "\n",
    "In some cases we might wish to know the avearge location of the head, body, arm or hand. To do this we average together all the points for a given body part and create a new time series for this point. Likewise we may with smooth the movement data by taking a moving average of several frames at once. Or look at the amount of movement by calculating a variance measure. \n",
    "\n",
    "\n",
    "We create a dictionary of the subsets of OpenPose coordinates we want to average (per frame) and then call `mean` on the Pandas dataframe. e.g.\n",
    "\n",
    "```\n",
    "meanpoints = {\n",
    "               \"headx\" : [0, 3, 45, 48, 51, 54],\n",
    "               \"heady\" : [1, 4, 46, 49, 52, 55],\n",
    "               \"allx\" :  [0, 3, 6, 9, ...],\n",
    "               \"ally\" :  [1, 4, 7, 10, ...]\n",
    "             }\n",
    "```\n",
    "\n",
    "Then we call the `vasc.averageCoordinateTimeSeries` function to average across sets of coordinates. For a given set of videos and people. For example\n",
    "\n",
    "In:\n",
    "```\n",
    "videos = \"All\"\n",
    "people = \"Both\"\n",
    "df2 = vasc.averageCoordinateTimeSeries(df,meanpoints,videos,people)\n",
    "df2.head\n",
    "```\n",
    "\n",
    "Out:\n",
    "```\n",
    "person      infant                                          parent\n",
    "avgs         headx       heady          xs          ys       headx\n",
    "501     565.996600  369.840600  534.895615  398.482538  471.686200\n",
    "502     567.231800  369.887600  534.354198  398.706552  471.849400\n",
    "503     567.228600  370.159600  534.444328  398.678133  471.711600\n",
    "504     566.912600  369.857000  535.369536  398.551636  472.309400\n",
    "...            ...         ...         ...         ...         ...\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "meanpoints = {\"head\" : vasc.headxys,\n",
    "              \"headx\": vasc.headx,\n",
    "              \"heady\": vasc.heady,\n",
    "              \"arms\" : vasc.armsxys,\n",
    "              \"armsx\": vasc.armsx,\n",
    "              \"armsy\": vasc.armsy,\n",
    "              \"leftarm\" : vasc.leftarmxys,\n",
    "              \"leftarmx\": vasc.leftarmx,\n",
    "              \"leftarmy\": vasc.leftarmy,\n",
    "              \"rightarm\" : vasc.rightarmxys,\n",
    "              \"rightarmx\": vasc.rightarmx,\n",
    "              \"rightarmy\": vasc.rightarmy,\n",
    "              \"all\"  : vasc.xys,\n",
    "              \"allx\" : vasc.xs,\n",
    "              \"ally\" : vasc.ys\n",
    "             }\n",
    "\n",
    "vids = \"All\"\n",
    "people = [\"infant\",\"parent\"]\n",
    "\n",
    "#average across the points in each group (all points of head etc. )\n",
    "avgdf = vasc.averageCoordinateTimeSeries(df,meanpoints,vids,people)\n",
    "\n",
    "\n",
    "if includeHands:\n",
    "    handpoints = {\"hand\" : vasc.hxys,\n",
    "           \"handx\" : vasc.hxs,\n",
    "           \"handy\" : vasc.hys}\n",
    "\n",
    "    avglh = vasc.averageCoordinateTimeSeries(lh,handpoints,vids,people)\n",
    "    avgrh = vasc.averageCoordinateTimeSeries(rh,handpoints,vids,people)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#optionally have a look\n",
    "avgdf.head"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2.3 Combining hand and wrist data\n",
    "\n",
    "If we have hand data from OpenPose then we can combine this with the body data to get more accurate movements for the left and right hands. Similar to what we did on the step before but combining across multiple dataframes.\n",
    "\n",
    "We use a weighted sum of the points from elbow, wrist and hand. With wrist weighted more heavily than individual hand points. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#to calculate the mean, we need to let routine know what points to use. \n",
    "#From the arm this the points we want to combine\n",
    "leftarmpoints = {\"hand\" : vasc.leftarmxys,\n",
    "               \"handx\": vasc.leftarmx,\n",
    "               \"handy\": vasc.leftarmy}\n",
    "\n",
    "rightarmpoints = {\"hand\" : vasc.rightarmxys,\n",
    "               \"handx\": vasc.rightarmx,\n",
    "               \"handy\": vasc.rightarmy}\n",
    "\n",
    "leftwristpoints = {\"hand\" : vasc.leftwristxys,\n",
    "               \"handx\": vasc.leftwristx,\n",
    "               \"handy\": vasc.leftwristy}\n",
    "\n",
    "rightwristpoints = {\"hand\" : vasc.rightwristxys,\n",
    "               \"handx\": vasc.rightwristx,\n",
    "               \"handy\": vasc.rightwristy}\n",
    "\n",
    "handpoints = {\"hand\" : vasc.hxys,\n",
    "       \"handx\" : vasc.hxs,\n",
    "       \"handy\" : vasc.hys}\n",
    "\n",
    "\n",
    "if includeHands:\n",
    "    rightarmhand = vasc.averageArmHandTimeSeries(df,rh,rightarmpoints,handpoints,vids,people)\n",
    "    leftarmhand  = vasc.averageArmHandTimeSeries(df,lh,leftarmpoints,handpoints,vids,people)\n",
    "\n",
    "    #combine hand and wrist data weighting in ratio\n",
    "    wristtohandweightratio = 21 #since the hand has 21 times more points than wrist but we want both to contribute\n",
    "\n",
    "    rightwristhand = vasc.averageArmHandTimeSeries(df,rh,rightwristpoints,handpoints,vids,people,wristtohandweightratio)\n",
    "    leftwristhand  = vasc.averageArmHandTimeSeries(df,lh,leftwristpoints,handpoints,vids,people, wristtohandweightratio)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rightwristhand"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2.4 Rolling window of movements\n",
    "\n",
    "One thing we'd like to know is if mothers move in response to infants. The raw time series are probably too noisy to tell us this so instead we can look at few alternatives\n",
    "\n",
    "1. **Smoothed** - if we average the signal over a short rolling window we smooth out any high-frequency jitter.\n",
    "2. **Variance** - the variance of movement over a short rolling window. First we apply short (10 frame) rolling window to each coordinate of the body and use the stddev or variance function `std()` or `var()` . Then we take averages as in the step above. However, this time we combine x and y coordinates as this is now a movement index.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "win = 10 #10 frames better for rhythm detcion\n",
    "halfwin = math.floor(win/2)\n",
    "\n",
    "smoothdf = df.rolling(window = 5).mean()\n",
    "smoothdf = smoothdf.truncate(before  = first, after = last)\n",
    "\n",
    "vardf = df.rolling(window = win, min_periods = halfwin).var()\n",
    "vardf = vardf.truncate(before  = first , after = last) # cut out the empty bits at the start\n",
    "\n",
    "smoothdf = vasc.averageCoordinateTimeSeries(smoothdf,meanpoints,vids,people)\n",
    "vardf = vasc.averageCoordinateTimeSeries(vardf,meanpoints,vids,people)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#smooth hand movement data\n",
    "smoothrightwristhand = rightwristhand.rolling(window = 5).mean()\n",
    "smoothleftwristhand = leftwristhand.rolling(window = 5).mean()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3.3 Visualising the data\n",
    "\n",
    "Let's create a widget to plot some graphs of the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "lines_to_next_cell": 0
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "396aaa4b39b74737a2d76f8e1026c290",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "vidlist = [] #used to fill dropdown options\n",
    "for vid in videos:\n",
    "    vidlist.append(vid)\n",
    "\n",
    "pickvid = widgets.Dropdown(\n",
    "    options= vidlist,\n",
    "    value= vidlist[0],\n",
    "    description='Subject:'\n",
    ")\n",
    "\n",
    "series = [\"Body\"]\n",
    "if includeHands:\n",
    "    series = [\"Body\",\"Left Hand\",\"Right Hand\",\"Left Arm & Hand\",\"Right Arm & Hand\",\"Left Wrist & Hand (Weighted)\",\"Right Wrist & Hand (Weighted)\"]\n",
    "\n",
    "pickseries = widgets.Dropdown(\n",
    "    options= series,\n",
    "    value= series[0],\n",
    "    description='Series:'\n",
    ")\n",
    "\n",
    "    \n",
    "mainfeatures = []\n",
    "for f in meanpoints:\n",
    "    mainfeatures.append(f)\n",
    "\n",
    "handfeatures = []\n",
    "for f in handpoints:\n",
    "    handfeatures.append(f)\n",
    "    \n",
    "\n",
    "pickfeature = widgets.Dropdown(\n",
    "    options= mainfeatures,\n",
    "    value= mainfeatures[0],\n",
    "    description='Feature:'\n",
    ")\n",
    "\n",
    "linetypes = [\"Mean point\", \"Smoothed Mean (5 frames)\",\"Variance over 2 secs\"]\n",
    "picktype = widgets.Dropdown(\n",
    "    options= linetypes,\n",
    "    value= linetypes[0],\n",
    "    description='Line type:'\n",
    ")\n",
    "\n",
    "def pickvid_change(change):\n",
    "    if change['name'] == 'value' and (change['new'] != change['old']):\n",
    "        updateAll(True)\n",
    "        \n",
    "def pickseries_change(change):\n",
    "    if change['name'] == 'value' and (change['new'] != change['old']):\n",
    "        if pickseries.value == series[0]:\n",
    "            pickfeature.options = mainfeatures\n",
    "        else:\n",
    "            pickfeature.options = handfeatures\n",
    "        updateAll(True)\n",
    "\n",
    "def pickfeature_change(change):\n",
    "    if change['name'] == 'value' and (change['new'] != change['old']):\n",
    "        updateAll(True)\n",
    "\n",
    "def picktype_change(change):\n",
    "    if change['name'] == 'value' and (change['new'] != change['old']):\n",
    "        updateAll(True)\n",
    "\n",
    "pickvid.observe(pickvid_change, 'value')\n",
    "pickseries.observe(pickseries_change, 'value')\n",
    "#pickfeature.observe(pickfeature_change, 'value')\n",
    "picktype.observe(picktype_change, 'value')\n",
    "button_update = widgets.Button(description=\"Redraw\")\n",
    "output = widgets.Output()\n",
    "\n",
    "txt = widgets.Label(value=\"Which arm and start/end points do we use?\")\n",
    "leftright = widgets.RadioButtons(\n",
    "    options=['left', 'right'],\n",
    "    value='right', # Defaults to 'pineapple'\n",
    "    description='Arm',\n",
    "    disabled=False\n",
    ")\n",
    "def leftright_change(change):\n",
    "    if change['name'] == 'value' and (change['new'] != change['old']):\n",
    "        videos[pickvid.value][\"camera1\"][\"side\"] = leftright.value\n",
    "\n",
    "leftright.observe(leftright_change,'value')\n",
    "\n",
    "## a couple of sliders to set the start and end points.\n",
    "startslider = widgets.IntSlider(\n",
    "    value=0,\n",
    "    min=0,\n",
    "    max=videos[pickvid.value][\"camera1\"][\"end\"] ,\n",
    "    step=1,\n",
    "    description='Start Frame:',\n",
    "    continuous_update=False,\n",
    "    orientation='horizontal',\n",
    "    readout=True,\n",
    "    readout_format='d',\n",
    "    layout=widgets.Layout(width='800px')\n",
    ")\n",
    "endslider = widgets.IntSlider(\n",
    "    value=161,\n",
    "    min=0,\n",
    "    max=161,\n",
    "    step=1,\n",
    "    description='End Frame:',\n",
    "    continuous_update=False,\n",
    "    orientation='horizontal',\n",
    "    readout=True,\n",
    "    readout_format='d',\n",
    "    layout=widgets.Layout(width='800px')\n",
    ")\n",
    "\n",
    "def slider_change(slider):\n",
    "    videos[pickvid.value][\"camera1\"][\"start\"] = startslider.value\n",
    "    videos[pickvid.value][\"camera1\"][\"end\"] = max(startslider.value,endslider.value) #can't go below start.\n",
    "    #logging.info (videos[vid][\"camera1\"])\n",
    "    updateAll(False)\n",
    "\n",
    "startslider.observe(slider_change, 'value')\n",
    "endslider.observe(slider_change, 'value')\n",
    "    \n",
    "def drawGraphs(vid, seriestype, feature, linetype):\n",
    "    \"\"\"Plot input signals\"\"\"\n",
    "    plt.ion()\n",
    "\n",
    "#    f,ax=plt.subplots(4,1,figsize=(14,10),sharex=True)\n",
    "    f,ax=plt.subplots(2,1,figsize=(14,6),sharex=False)\n",
    "    ax[0].set_title('Infant')\n",
    "    ax[0].set_xlabel('Frames')\n",
    "#    ax[1].set_title('Parent')\n",
    "    ax[1].set_xlabel('Seconds')\n",
    "\n",
    "    who = [\"infant\",\"parent\"]\n",
    "\n",
    "    #what time series (smoothed, etc) are we plotting?\n",
    "    if linetype == linetypes[0]:\n",
    "        usedf = avgdf\n",
    "    elif linetype == linetypes[1]:\n",
    "        usedf = smoothdf\n",
    "    else:\n",
    "        usedf = vardf\n",
    "    \n",
    "    #now pick the correct dataseries\n",
    "    if seriestype == series[0]:\n",
    "        #nothing to change\n",
    "        usedf = usedf\n",
    "    elif seriestype == series[1]:\n",
    "        usedf = avglh\n",
    "    elif seriestype == series[2]:\n",
    "        usedf = avgrh\n",
    "    elif seriestype == series[3]:\n",
    "        usedf = leftarmhand\n",
    "    elif seriestype == series[4]:\n",
    "        usedf = rightarmhand\n",
    "    elif seriestype == series[5]:\n",
    "        usedf = leftwristhand\n",
    "    elif seriestype == series[6]:\n",
    "        usedf = rightwristhand    \n",
    "    else:\n",
    "        raise ValueError(\"Unknown series type selected\")\n",
    "\n",
    "    #to select a single column..\n",
    "    infant = usedf[(vid, people[0], feature)].to_frame()\n",
    "    parent = usedf[(vid, people[1], feature)].to_frame()\n",
    "    n  = np.arange(usedf.shape[0])\n",
    "\n",
    "    #selecting multiple columns slightly messier\n",
    "    #infant = df3.loc[50:,(vid, part[0], ('head','arms', 'all'))]\n",
    "    #parent = df3.loc[50:,(vid, part[1], ('head','arms', 'all'))]\n",
    "\n",
    "    fps = videos[vid]['camera1']['fps']  \n",
    "    x_time = n / fps #scale by frame per second to get real time\n",
    "    ax[0].plot(infant)\n",
    "    #add vertical lines for the start and end points for analysis\n",
    "    #todo make vertical lines work as times\n",
    "    starttime = videos[vid][\"camera1\"][\"start\"] \n",
    "    endtime = videos[vid][\"camera1\"][\"end\"]  \n",
    "    #logging.info(videos[vid][\"camera1\"])\n",
    "    ax[0].axvline(x=starttime,c='tab:green')\n",
    "    ax[0].axvline(x=endtime,c='tab:red')\n",
    "    ax[1].plot(x_time, infant /fps)\n",
    "#    ax[1].plot(parent, color='b')\n",
    "    \n",
    "#    ax[2].plot(usedf.loc[:,(vid, slice(None), feature)])\n",
    "#    ax[2].set(xlabel='Time',ylabel='Movement index for parent and infant')\n",
    "\n",
    "#    if seriestype == series[0]:\n",
    "#        #calculate the correlations in a shorter rolling window\n",
    "#        r_window_size = 120\n",
    "#        rolling_r = usedf[(vid, who[0], feature)].rolling(window=r_window_size, center=True).corr(vardf[(vid, who[1], feature)])\n",
    "#        rolling_r.plot(ax=ax[3])\n",
    "#        ax[3].set(xlabel='Time (seconds)',ylabel='Pearson r')\n",
    "#        ax[3].set_title(\"Local correlation with rolling window size \" + str(r_window_size))\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "def updateAll(forceUpdate = False):\n",
    "    output.clear_output(wait = True)   \n",
    "    if forceUpdate:\n",
    "        fps = videos[pickvid.value]['camera1']['fps']  \n",
    "        startslider.max =  videos[pickvid.value][\"camera1\"][\"frames\"]\n",
    "        endslider.max =  videos[pickvid.value][\"camera1\"][\"frames\"]  \n",
    "        leftright.value = videos[pickvid.value][\"camera1\"][\"side\"] \n",
    "        logging.debug('forceUpdate')\n",
    "    with output:\n",
    "        display(pickvid,pickseries,pickfeature,picktype,txt,leftright,startslider,endslider,button_update)\n",
    "        drawGraphs(pickvid.value,pickseries.value,pickfeature.value,picktype.value)\n",
    "\n",
    "#draw everything for first time\n",
    "updateAll(True)\n",
    "output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Setting at start time across all videos\n",
    "\n",
    "The next cell loops through all entries in `clean.json` and sets the `start` time the same for all cases. \n",
    "Remember that video data is frame by frame and each video could have a different frame rate (`fps`). So we\n",
    "need to convert time into frames.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "starttime = 0 \n",
    "starttime = 5  #(in seconds)\n",
    "\n",
    "for vid in videos:\n",
    "    for cam in videos[vid]:\n",
    "        videos[vid][cam][\"side\"] = \"right\"\n",
    "        videos[vid][cam][\"start\"] = int(starttime * videos[vid][cam][\"fps\"]) #convert time to number of frames\n",
    "        videos[vid][cam][\"end\"] = videos[vid][cam][\"frames\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "who = [\"infant\",\"parent\"]\n",
    "parts = [\"head\",\"arms\",\"all\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3.4 Read in behavioural coding from Spreadsheet\n",
    "\n",
    "We load the data from the spreadsheet `LittleDrummers_TutorialManualCoding.xlsx`. \n",
    "\n",
    "The worksheet `ManualCoding` contains one row per participant and includes the participant ids, the condition they are in, human rating of whether they drumming, whether this was visible on camera and which hand or hands they used. \n",
    "\n",
    "The worksheet `Fourier.All` contains one row per video and includes the participant ids, the trial number (SMT1, 1, 2, 3, 4, SMT2), and for each hand - the peak frequency from the fourier analysis for that video and power at several different target frequencies (400,500,600,700).\n",
    "\n",
    "We combine these to find group level performance. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "excelfile = videos_out  + \"\\\\LittleDrummers_TutorialManualCoding.xlsx\"\n",
    "\n",
    "manualcoding = pd.read_excel(excelfile, sheet_name = \"ManualCoding\",  header=[0,1])\n",
    "\n",
    "#fourier = pd.read_excel(excelfile, sheet_name = \"Fourier.All.0.5Hzcuttoff\",  header=[0,1])\n",
    "fourier = pd.read_excel(excelfile, sheet_name = \"Fourier.All.1.0Hzcuttoff\",  header=[0,1])\n",
    "\n",
    "nchildren = len(manualcoding)\n",
    "\n",
    "print(f\"ManualCoding sheet contains {nchildren} rows.\")\n",
    "\n",
    "print(f\"Fourier data sheet contains {len(fourier)} rows.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3.4.1 Find trial info\n",
    "\n",
    "For each trail we need to know the target inter stimulus interval (ISI) for each trial. For children in condition 0 the trial order was (400, 600, 500, 700), in condition 1 the order was (700,500,600,400). Then we need to know "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create a look up arrays to find out the ISI for each trial + condition\n",
    "orders =  [[400, 600, 500, 700],[700,500,600,400]]\n",
    "#And a data structure to do the reverse find Trial from targetISI and condition \n",
    "trialNames = {400: {0:\"Trial1\", 1:\"Trial4\"},\n",
    "          500: {0:\"Trial3\", 1:\"Trial2\"},\n",
    "          600: {0:\"Trial2\", 1:\"Trial3\"},\n",
    "          700: {0:\"Trial4\", 1:\"Trial1\"},\n",
    "          \"SMT1\": {0:\"SMT1\", 1:\"SMT1\"}, #SMT trials not affected by condition\n",
    "          \"SMT2\": {0:\"SMT2\", 1:\"SMT2\"}\n",
    "         }\n",
    "trialTypes = {\"Trial1\": {0:400, 1:700},\n",
    "              \"Trial2\": {0:600, 1:500},\n",
    "              \"Trial3\": {0:500, 1:600},\n",
    "              \"Trial4\": {0:700, 1:400},\n",
    "              \"SMT1\": {0:\"SMT1\", 1:\"SMT1\"}, #SMT trials not affected by condition\n",
    "              \"SMT2\": {0:\"SMT2\", 1:\"SMT2\"}\n",
    "         }\n",
    "\n",
    "def vidStringtoTrialName(vidString):\n",
    "# function to work out trial type from filename\n",
    "    lookitStep = int(vidString[8:10])\n",
    "    if lookitStep == 4:\n",
    "        trialName = \"SMT1\"\n",
    "    elif lookitStep == 14:\n",
    "        trialName  = \"SMT2\"\n",
    "    else:\n",
    "        idx = (lookitStep -6) // 2\n",
    "        trialName = \"Trial\" + str(1+idx)\n",
    "    return trialName"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#see if it works as expected\n",
    "print(trialNames[500][0])\n",
    "print(trialTypes[\"Trial4\"][1])\n",
    "vidstring = \"16d2b71_12-test-trials\"\n",
    "print(vidStringtoTrialName(vidstring))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def TrialInfo(manualcodingsheet, fourier, vidString):\n",
    "    # uses info in our manual coding spreadsheet to determine if\n",
    "    # 1. this is a valid trial (e.g. not an aborted recording)\n",
    "    # 2. then if hands are in view and if there is drumming with left or right hand\n",
    "    \n",
    "    \n",
    "    trial = lambda: None   #Standard hack to create an object with dynamic properties\n",
    "    trial.error = \"\"\n",
    "    \n",
    "    trial.ID = vidString[0:7]\n",
    "    #can we find this child?\n",
    "    child = manualcoding[manualcoding[\"ChildID\",\"ChildID\"] == trial.ID]\n",
    "    if len(child) != 1:\n",
    "        trial.error = \"There were \" + str(len(child)) + \" entries found for ID = \" + trial.ID + \" (Expecting 1.)\"\n",
    "        return trial\n",
    "        \n",
    "\n",
    "    #work out trial name (SMT1, Trial1, etc from video name)\n",
    "    trial.name = vidStringtoTrialName(vidString)\n",
    "    \n",
    "\n",
    "    #get manual coding data for this id\n",
    "    coded = fourier[(fourier[\"ChildID\",\"ChildID\"]  == trial.ID) & (fourier[\"TrialID\",\"TrialID\"] == trial.name)]\n",
    "    if len(coded) != 1:\n",
    "        trial.error = \"There were \" + str(len(coded)) + \" fourier entries found for ID = \" + trial.ID + \" (Expecting 1.)\"\n",
    "        return trial\n",
    "    else:\n",
    "        fidx = coded.index[0]\n",
    "        fouriervideo = coded.at[fidx, (\"VideoName\",\"VideoName\")]\n",
    "        if vidString != fouriervideo:\n",
    "            trial.error = \"Video \" + vidString + \" is not used for \" + trial.name + \" Expecting \" + fouriervideo \n",
    "            return trial\n",
    "        \n",
    "    rowidx = child.index[0]\n",
    "    \n",
    "    #trial.ID = child.at[rowidx, (\"ChildID\",\"ChildID\")]\n",
    "    trial.respcompleted = child.at[rowidx, (\"response_completed\",\"response_completed\")]\n",
    "    trial.withdrawn = child.at[rowidx, (\"response_withdrawn\",\"response_withdrawn\")]\n",
    "    trial.condition = child.at[rowidx, (\"response_condition\",\"response_condition\")]\n",
    "    \n",
    "    \n",
    "    trial.ISI = trialTypes[trial.name][trial.condition]\n",
    "    if isinstance(trial.ISI, (str)): #an SMT trial\n",
    "        trial.desc = trial.name \n",
    "        trial.freq = \"\"\n",
    "        trial.filename = trial.name\n",
    "    else:\n",
    "        trial.desc = trial.name + \" \" + \"Target ISI: \" + str(trial.ISI) + \"ms\"\n",
    "        trial.freq = \"Target freq: {:.2f} Hz\".format(1000/trial.ISI)\n",
    "        trial.filename = trial.name + \".\" + str(trial.ISI) + \"ms\"\n",
    "    \n",
    "    trial.cleaned = child.at[rowidx, (trial.name,\"Data cleaned\")]\n",
    "    trial.attempted = child.at[rowidx, (trial.name,\"Trial Attempted\")]\n",
    "    trial.respcompleted = child.at[rowidx, (trial.name,\"Trial Complete\")]\n",
    "    trial.inView = child.at[rowidx, (trial.name,\"In View\")]\n",
    "    trial.infantDrum = child.at[rowidx, (trial.name,\"Infant Drum\")]\n",
    "    trial.rightHand = child.at[rowidx, (trial.name,\"Right Hand\")]\n",
    "    trial.leftHand = child.at[rowidx, (trial.name,\"Left Hand\")]\n",
    "\n",
    "    return trial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def annotate_axes(ax, text, fontsize=18):\n",
    "    ax.text(0.5, 0.3, text, transform=ax.transAxes,\n",
    "            ha=\"center\", va=\"center\", fontsize=fontsize, color=\"darkgrey\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "trial = TrialInfo(manualcoding, fourier,vidstring)\n",
    "print(trial.ID)\n",
    "print(trial.respcompleted)\n",
    "print(trial.inView )\n",
    "\n",
    "\n",
    "if trial.respcompleted and not trial.withdrawn and trial.cleaned: #is this valid data?\n",
    "    if trial.attempted and trial.inView and trial.infantDrum: #was there any (visible) drumming?\n",
    "        print(trial.leftHand,trial.rightHand)\n",
    "    else:\n",
    "         print(\"no drumming\")\n",
    "else:\n",
    "    print(\"Not a valid trial\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 0
   },
   "outputs": [],
   "source": [
    "#number of participants, average age\n",
    "ps = manualcoding[manualcoding[\"include\",\"include\"] == True]\n",
    "excl =manualcoding[manualcoding[\"include\",\"include\"] == False]\n",
    "\n",
    "age = ps[\"child_age_rounded\",\"child_age_rounded\"]\n",
    "print(\"Mean age {:.1f}, +/- {:.1f}, min {:.1f} max {:.1f}\".format(age.mean(), age.std(),age.min(),age.max()))\n",
    "\n",
    "gender = np.unique(ps[\"child_gender\",\"child_gender\"], return_counts=True)\n",
    "\n",
    "print(len(ps))\n",
    "print(gender)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## 3.5 Finding fundamental frequency with FFT\n",
    "\n",
    "\n",
    "A good guide can be found here https://realpython.com/python-scipy-fft/\n",
    "\n",
    "Filtering explained here https://scipy-lectures.org/intro/scipy/auto_examples/plot_fftpack.html\n",
    "\n",
    "\n",
    "In this first block of code we want to see the freequency power at each target ISI/frequency and the absolute peak "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_end_of_cell_marker": 2,
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "plotgraphs = True\n",
    "savegraphs = False #save figs to png rather than on screen\n",
    "savedata = True\n",
    "\n",
    "\n",
    "leftdf = leftwristhand\n",
    "rightdf = rightwristhand\n",
    "\n",
    "bodypart = 'handy'\n",
    "\n",
    "failarray = [math.nan, math.nan, math.nan, math.nan, math.nan, math.nan]  #empty array if we fail to fit function\n",
    "\n",
    "resultRight = pd.DataFrame(columns = (\"peakfreq\",\"peakpower\", \"400\",\"500\",\"600\",\"700\",\"fps\",\"message\"), index = videos)\n",
    "resultLeft = pd.DataFrame(columns = (\"peakfreq\",\"peakpower\", \"400\",\"500\",\"600\",\"700\",\"fps\",\"message\"), index = videos)\n",
    "\n",
    "halfbinwidth = 4\n",
    "targetFreqs = [1000/400, 1000/500, 1000/600, 1000/700]\n",
    "#freqResults =pd.DataFrame(columns = (\"SMT450\",\"ISI400\",\"ISI500\",\"ISI600\",\"ISI700\"))\n",
    "\n",
    "#what is the lower end cutoff in Hertz? \n",
    "#note - since each video has a different speed (diff fps) we need to convert/this value for each vid.\n",
    "lowendcutoffinHz = 1.0\n",
    "\n",
    "\n",
    "for vid in videos:\n",
    "    trial = TrialInfo(manualcoding,fourier, vid)\n",
    "    if len(trial.error) > 0:\n",
    "        print(vid, \"No data: \" + trial.error)\n",
    "    elif not trial.respcompleted or trial.withdrawn or not trial.cleaned: #is this valid data?\n",
    "        print(\"ID: \" + trial.ID, trial.desc, \"No clean data\" )\n",
    "    elif not trial.attempted or not trial.inView or not trial.infantDrum: \n",
    "        print(\"ID: \" + trial.ID, trial.desc, \"No visible drumming\")\n",
    "    else: \n",
    "        print(\"ID: \" + trial.ID, trial.desc, trial.freq)\n",
    "        #retrieve the raw data for this video\n",
    "        frames = videos[vid]['camera1']['frames']    #how many frames?\n",
    "        start = videos[vid][cam][\"start\"] \n",
    "        end = videos[vid][cam][\"end\"]\n",
    "        sampleframes = end - start\n",
    "        fps = videos[vid]['camera1']['fps']          #how many frames per second?\n",
    "        x_data = np.linspace(start,end,sampleframes+1)      #x axis\n",
    "        x_time = x_data / fps                        #x axis in units of time (seconds)\n",
    "        if plotgraphs:\n",
    "            fig, axs = plt.subplots(ncols=4, nrows=1, figsize=(18, 4), constrained_layout=True)\n",
    "\n",
    "        for side in [0, 1]: #0 = left, 1 = right\n",
    "            if side == 0:\n",
    "                whichdf = leftdf\n",
    "                havedata = trial.leftHand\n",
    "                title = \"Left\"\n",
    "            else:\n",
    "                whichdf = rightdf\n",
    "                havedata = trial.rightHand\n",
    "                title = \"Right\"\n",
    "\n",
    "            if not havedata:\n",
    "                annotate_axes(axs[2*side], \"No drumming\")\n",
    "                annotate_axes(axs[2*side + 1], \"No drumming\")\n",
    "                axs[2*side].set_axis_off()\n",
    "                axs[2*side + 1].set_axis_off()\n",
    "            else:\n",
    "                armmov = whichdf[(vid, people[0], bodypart)]  #get the averaged data\n",
    "                y_data = armmov.truncate(before = start, after = end).to_numpy()  #convert to numpy array\n",
    "\n",
    "                #we are just interested in the periodic elements (not absolute value above zero) so substract the mean\n",
    "                y_normed = np.subtract(y_data,np.average(y_data))\n",
    "\n",
    "                try:\n",
    "                    yfft = scipy.fft.rfft(y_normed)\n",
    "                    power = np.abs(yfft)**2\n",
    "                    xfreq = scipy.fft.rfftfreq(x_data.size, 1 / fps)\n",
    "\n",
    "                    #frequency cutoff at the lower end \n",
    "                    #as these frequencies are not relevant  \n",
    "                    power[np.abs(xfreq) < lowendcutoffinHz] = 0\n",
    "\n",
    "                    #let's find the maximum frequency.\n",
    "                    #we hope this is infant's repetitive movement\n",
    "                    mY = np.abs(power) # Find magnitude\n",
    "                    peakY = np.max(mY) # Find max peak\n",
    "                    locY = np.argmax(mY) # Find its location\n",
    "                    frqY = xfreq[locY] # Get the actual frequency value\n",
    "                    #print(frqY)\n",
    "\n",
    "                    #let's find the power in a given frequency bucket corresponding to target freq\n",
    "                    buckets = [0,0,0,0]\n",
    "                    powers = [0,0,0,0]\n",
    "                    for p in range(4):\n",
    "                        #find the nearest value in our list to\n",
    "                        bucket =  np.argmax(xfreq>targetFreqs[p])\n",
    "                        buckets[p] = xfreq[bucket]\n",
    "                        powers[p] = sum(mY[bucket-halfbinwidth:bucket+halfbinwidth])\n",
    "\n",
    "                    #print(\"buckets:\", buckets)\n",
    "                    #print(\"powers: \",powers)\n",
    "\n",
    "                    if plotgraphs:\n",
    "\n",
    "                        #plot the vertical movement of this hand\n",
    " \n",
    "                        axs[2*side].plot(x_time, y_normed)\n",
    "                        axs[2*side].title.set_text(title + \" hand vertical\")\n",
    "                        axs[2*side].set_xlabel('Time (s)')\n",
    "                        axs[2*side].set_ylabel('Vertical movement')\n",
    "\n",
    "                        #now plot the Fourier power \n",
    "                        axs[2*side + 1].plot(xfreq, power)\n",
    "                        # New - Plot the max point\n",
    "                        axs[2*side + 1].plot(frqY, peakY, 'b.', markersize=18)\n",
    "                        # Rest of the code is the same\n",
    "                        axs[2*side + 1].set_xlabel('Freq (Hz)')\n",
    "                        axs[2*side + 1].set_ylabel('Power')\n",
    "                        axs[2*side + 1].set_xlim(right=6)\n",
    "                        #make title reflecting peak information\n",
    "                        axs[2*side + 1].title.set_text('Peak freq: {:.2f} Hz, power: {:.0f}'.format(frqY,peakY))\n",
    "                        \n",
    "                        annotate_axes(axs[2*side], trial.desc)\n",
    "                        annotate_axes(axs[2*side + 1], trial.freq)\n",
    "\n",
    "\n",
    "                    if savedata:\n",
    "                        #save all values to dataframe\n",
    "                        vals = []\n",
    "                        vals.append(frqY)  #max frequency\n",
    "                        vals.append(peakY)  #max power\n",
    "                        vals.extend(powers)\n",
    "                        vals.append(fps)\n",
    "                        vals.append(\"Success\")\n",
    "                        #print(\"this row: \", vals)\n",
    "                        if side == 0:\n",
    "                            resultLeft.loc[vid] = vals\n",
    "                        else:\n",
    "                            resultRight.loc[vid] = vals\n",
    "                        \n",
    "\n",
    "                except Exception as e:\n",
    "                    #emsg = \"\".join(str(e)) #error message string hack :(\n",
    "                    emsg = str(e)\n",
    "                    #show the error\n",
    "                    print(vid, \" Error: \",emsg)\n",
    "                    if savedata:\n",
    "                        #record error in our results array\n",
    "                        vals = failarray.copy()\n",
    "                        vals.append(fps)\n",
    "                        vals.append(emsg)\n",
    "                        print(vals)\n",
    "                        results.loc[vid] = vals\n",
    "            \n",
    "        if savegraphs:\n",
    "            plt.savefig(f\"{videos_out}\\\\plots\\\\{trial.ID}.{trial.filename}.png\")\n",
    "            plt.close()\n",
    "        else:\n",
    "            plt.show()\n",
    "            plt.close()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#save the fitted parameters.\n",
    "resultLeft.to_excel(videos_out  + \"\\\\LeftHand.FixedBinFreq.xlsx\")\n",
    "resultRight.to_excel(videos_out  + \"\\\\RightHand.FixedBinFreq.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plotHistograms(targetISI,fs):\n",
    "    # the histogram of the data\n",
    "    binList = np.linspace(1.00,3.6,14)\n",
    "    n, bins, patches = plt.hist(fs, bins = binList , density=False, facecolor='g', alpha=0.75)\n",
    "\n",
    "    plt.xlabel('Frequency bins (Hz)')\n",
    "    plt.ylabel('Count')\n",
    "    if isinstance(targetISI, (str)):\n",
    "        plt.title('Histogram of Drumming Frequencies for ' + targetISI)\n",
    "    else:\n",
    "        plt.title('Histogram of Drumming Frequencies for target {:.2f} Hz'.format(1000/targetISI))\n",
    "\n",
    "    #plt.text(60, .025, r'$\\mu=100,\\ \\sigma=15$')\n",
    "    #plt.xlim(40, 160)\n",
    "    #plt.ylim(0, 0.03)\n",
    "    plt.grid(True)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for targetISI in [\"SMT1\",\"SMT2\",400,500,600,700]:\n",
    "    fs = []\n",
    "    for vid in videos:\n",
    "        trial = TrialInfo(manualcoding,fourier, vid)\n",
    "        if len(trial.error) == 0:\n",
    "            if trial.respcompleted and not trial.withdrawn and trial.cleaned: #is this valid data?\n",
    "                if trial.attempted and trial.inView and trial.infantDrum: #was there any (visible) drumming?\n",
    "                    if trial.ISI == targetISI:\n",
    "                        #select all the fourier data for this child\n",
    "                        freqpower = fourier[fourier['ChildID','ChildID'] == trial.ID]\n",
    "                        if trial.leftHand and trial.rightHand:\n",
    "                            l = float(freqpower[freqpower['TrialID','TrialID'] == trial.name][\"Left\",\"peakpower\"])\n",
    "                            r = float(freqpower[freqpower['TrialID','TrialID'] == trial.name][\"Right\",\"peakpower\"])\n",
    "                            #select the hand with greatest power\n",
    "                            side = (\"Right\" if r > l else \"Left\")\n",
    "                            f = float(freqpower[freqpower['TrialID','TrialID'] == trial.name][side,\"peakfreq\"])\n",
    "                        elif trial.rightHand:\n",
    "                            f = float(freqpower[freqpower['TrialID','TrialID'] == trial.name][\"Right\",\"peakfreq\"])\n",
    "                        elif trial.leftHand:\n",
    "                            f = float(freqpower[freqpower['TrialID','TrialID'] == trial.name][\"Left\",\"peakfreq\"])\n",
    "                        else:\n",
    "                            f = None\n",
    "                        #print(trial.ID, trial.name, trial.ISI, trial.leftHand, trial.rightHand,f)\n",
    "                        #print(f)\n",
    "                        fs.append(f)\n",
    "\n",
    "    print(len(fs))\n",
    "    plotHistograms(targetISI,fs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 0
   },
   "outputs": [],
   "source": [
    "def AbsolutePowerGraph(targetISI,powerinband):\n",
    "    means3 = powerinband.agg([np.mean, np.std])\n",
    "    means3.T.plot(kind = \"bar\", y = \"mean\", legend = False,\n",
    "                title = \"Average power per ISI freqs for target ISI = \" + targetISI + \"ms\", yerr = \"std\")\n",
    "    \n",
    "def RelativePowerGraph(targetISI,powerinband):\n",
    "    normalise = powerinband.iloc[:, 1:5]\n",
    "    normalise = normalise.div(normalise.sum(axis=1), axis=0)\n",
    "\n",
    "    means3 = normalise.agg([np.mean, np.std])\n",
    "    means3.T.plot(kind = \"bar\", y = \"mean\", legend = False,\n",
    "                title = \"Relative power per ISI freqs for target ISI = \" + targetISI + \"ms\", yerr = \"std\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 0
   },
   "outputs": [],
   "source": [
    "\n",
    "for targetISI in [400,500,600,700]:\n",
    "    \n",
    "    #data structure to store power found in target bands\n",
    "    powerinband = pd.DataFrame(columns = (\"ID\", \"400\",\"500\",\"600\",\"700\"))\n",
    "    \n",
    "    for vid in videos:\n",
    "        trial = TrialInfo(manualcoding,fourier, vid)\n",
    "        onerow = {}\n",
    "        if len(trial.error) == 0:\n",
    "            if trial.respcompleted and not trial.withdrawn and trial.cleaned: #is this valid data?\n",
    "                if trial.attempted and trial.inView and trial.infantDrum: #was there any (visible) drumming?\n",
    "                    if trial.ISI == targetISI:    \n",
    "                        #select all the fourier data for this child\n",
    "                        freqpower = fourier[fourier['ChildID','ChildID'] == trial.ID]\n",
    "\n",
    "                        for frequencyBand in [\"400\",\"500\",\"600\",\"700\"]:\n",
    "                            if trial.leftHand and trial.rightHand:\n",
    "                                l = float(freqpower[freqpower['TrialID','TrialID'] == trial.name][\"Left\",frequencyBand])\n",
    "                                r = float(freqpower[freqpower['TrialID','TrialID'] == trial.name][\"Right\",frequencyBand])\n",
    "                                p = max(l,r)\n",
    "                            elif trial.rightHand:\n",
    "                                p = float(freqpower[freqpower['TrialID','TrialID'] == trial.name][\"Right\",frequencyBand])\n",
    "                            elif trial.leftHand:\n",
    "                                p = float(freqpower[freqpower['TrialID','TrialID'] == trial.name][\"Left\",frequencyBand])\n",
    "                            else:\n",
    "                                p = None\n",
    "                            onerow[frequencyBand] = p\n",
    "                        \n",
    "                        #print(onerow)\n",
    "                        powerinband = powerinband.append(onerow, ignore_index=True)\n",
    "    \n",
    "    RelativePowerGraph(str(targetISI),powerinband)\n",
    "    #AbsolutePowerGraph(str(targetISI),powerinband)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3.6 Child drumming accuracy\n",
    "\n",
    "For each child we want to compare the drumming they did to the target shown on the screen. So collect together all the (non-SMT) trials in which there was drumming and show the peak Freq, ISI for each hand (that drums). The 'best' hand is defined to be the hand which the greater power at the peak frequency."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data structure to store power found in target bands\n",
    "drummingaccuracy = pd.DataFrame(columns = (\"ChildID\", \"Trial\", \"TargetISI\",\"TargetHz\", \"BestISI\",\"BestHz\",\"LeftISI\",\"LeftHz\",\"RightISI\",\"RightHz\"))\n",
    "\n",
    "for vid in videos:\n",
    "    trial = TrialInfo(manualcoding,fourier, vid)\n",
    "    onerow = {}\n",
    "    if len(trial.error) == 0:\n",
    "        if trial.respcompleted and not trial.withdrawn and trial.cleaned: #is this valid data?\n",
    "            if trial.attempted and trial.inView and trial.infantDrum: #was there any (visible) drumming?\n",
    "                onerow[\"ChildID\"] = trial.ID\n",
    "                onerow[\"Trial\"] = trial.name\n",
    "                onerow[\"TargetISI\"] = trial.ISI\n",
    "                if isinstance(trial.ISI, (str)):\n",
    "                    onerow[\"TargetHz\"] = None\n",
    "                else:\n",
    "                    onerow[\"TargetHz\"] = 1000/trial.ISI\n",
    "                \n",
    "                #select all the fourier data for this child\n",
    "                freqpower = fourier[fourier['ChildID','ChildID'] == trial.ID]\n",
    "\n",
    "                #there's probably a more succint way to do this :-p\n",
    "                if trial.leftHand and trial.rightHand:\n",
    "                    onerow[\"LeftHz\"] = float(freqpower[freqpower['TrialID','TrialID'] == trial.name][\"Left\",\"peakfreq\"])\n",
    "                    onerow[\"LeftISI\"] = 1000 / onerow[\"LeftHz\"] \n",
    "                    onerow[\"RightHz\"] = float(freqpower[freqpower['TrialID','TrialID'] == trial.name][\"Right\",\"peakfreq\"])\n",
    "                    onerow[\"RightISI\"] = 1000 / onerow[\"RightHz\"] \n",
    "                    onerow[\"BestHz\"] = max(onerow[\"LeftHz\"] ,onerow[\"RightHz\"] )\n",
    "                    onerow[\"BestISI\"] = 1000 / onerow[\"BestHz\"] \n",
    "                elif trial.rightHand:                    \n",
    "                    onerow[\"LeftHz\"] = None\n",
    "                    onerow[\"LeftISI\"] = None\n",
    "                    onerow[\"RightHz\"] = float(freqpower[freqpower['TrialID','TrialID'] == trial.name][\"Right\",\"peakfreq\"])\n",
    "                    onerow[\"RightISI\"] = 1000 / onerow[\"RightHz\"] \n",
    "                    onerow[\"BestHz\"] = onerow[\"RightHz\"] \n",
    "                    onerow[\"BestISI\"] = 1000 / onerow[\"BestHz\"] \n",
    "                elif trial.leftHand:\n",
    "                    onerow[\"LeftHz\"] = float(freqpower[freqpower['TrialID','TrialID'] == trial.name][\"Left\",\"peakfreq\"])\n",
    "                    onerow[\"LeftISI\"] = 1000 / onerow[\"LeftHz\"] \n",
    "                    onerow[\"RightHz\"] = None\n",
    "                    onerow[\"RightISI\"] = None\n",
    "                    onerow[\"BestHz\"] = onerow[\"LeftHz\"]\n",
    "                    onerow[\"BestISI\"] = 1000 / onerow[\"BestHz\"] \n",
    "                else:\n",
    "                    print(f\"In theory this can't happen. No left or right drumming data for {vid}\")\n",
    "                \n",
    "                #print(onerow)\n",
    "                drummingaccuracy = drummingaccuracy.append(onerow, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    \n",
    "drummingaccuracy.to_excel(videos_out  + \"\\\\DrummingAccuracy.xlsx\")"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "formats": "ipynb,py:light"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
