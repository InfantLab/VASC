{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Video Actor Synchroncy and Causality (VASC)\n",
    "## RAEng: Measuring Responsive Caregiving Project\n",
    "### Caspar Addyman, 2020\n",
    "### https://github.com/infantlab/VASC\n",
    "\n",
    "# Step 3: Analyse the data using scipy\n",
    "\n",
    "This script uses output from [OpenPose](https://github.com/CMU-Perceptual-Computing-Lab/openpose) human figure recognition neural network to create labeled wireframes for each figure in each frame of a video. It uses the Python API version of OpenPose.\n",
    "\n",
    "\n",
    "\n",
    "https://towardsdatascience.com/granger-causality-and-vector-auto-regressive-model-for-time-series-forecasting-3226a64889a6\n",
    "\n",
    "https://www.machinelearningplus.com/time-series/time-series-analysis-python/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Automatic pdb calling has been turned ON\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "import json\n",
    "import numpy as np       #tools for numerical data\n",
    "import pandas as pd      #data tables & time series\n",
    "import matplotlib.pyplot as plt # Plotting package\n",
    "\n",
    "import logging\n",
    "import ipywidgets as widgets  #let's us add buttons and sliders to this page.\n",
    "from ipycanvas import Canvas\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import vasc #a module of our own functions (found in vasc.py in this folder)\n",
    "\n",
    "#turn on debugging\n",
    "logger = logging.getLogger()\n",
    "logger.setLevel(logging.INFO)\n",
    "%pdb on   \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\cas\\OneDrive - Goldsmiths College\\Projects\\Measuring Responsive Caregiving\\VASC\\..\\lookit\\out\\openpose\n",
      "C:\\Users\\cas\\OneDrive - Goldsmiths College\\Projects\\Measuring Responsive Caregiving\\VASC\\..\\lookit\\out\\timeseries\n",
      "C:\\Users\\cas\\OneDrive - Goldsmiths College\\Projects\\Measuring Responsive Caregiving\\VASC\\..\\lookit\\out\\analyses\n"
     ]
    }
   ],
   "source": [
    "# where's the project folder?\n",
    "jupwd =  os.getcwd() + \"\\\\\"\n",
    "projectpath = os.getcwd() + \"\\\\..\\\\lookit\\\\\"\n",
    "#projectpath = os.getcwd() + \"\\\\\"\n",
    "\n",
    "# locations of videos and output\n",
    "videos_in = projectpath \n",
    "videos_out   = projectpath + \"out\"\n",
    "#videos_out = \"E:\\\\SpeakNSign\\\\out\"\n",
    "videos_out_openpose   = videos_out + \"\\\\openpose\"\n",
    "videos_out_timeseries = videos_out + \"\\\\timeseries\"\n",
    "videos_out_analyses   = videos_out + \"\\\\analyses\"\n",
    "\n",
    "print(videos_out_openpose)\n",
    "print(videos_out_timeseries)\n",
    "print(videos_out_analyses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#retrieve the list of base names of processed videos.\n",
    "with open(videos_out + '\\\\clean.json') as json_file:\n",
    "    videos = json.load(json_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10, 3, 412, 4, 75)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#can reload the values without recomputing\n",
    "reloaded = np.load(videos_out_timeseries + '\\\\cleandata.npz')\n",
    "keypoints_original = reloaded[\"keypoints_array\"] #the unprocessed data\n",
    "keypoints_array = np.copy(keypoints_original)  #an array where we clean the data.\n",
    "\n",
    "keypoints_array.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SyncPy Correlation example\n",
    "\n",
    "It computes the linear correlation between two monovariate signals x and y (in DataFrame format) as a function of their delay tau.\n",
    "It computes autocorrelation when y coincides with x. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.insert(0, '../SyncPy/src/')   # To be able to import packages from parent directory\n",
    "sys.path.insert(0, '../SyncPy/src/Methods')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "************************************************************************************************\n",
      "This scripts computes the correlation between two monovariate signals.First input is a sinewave of 1 Hz frequency, the second one\n",
      " is the sum of this sinewavewith a gaussian random process having zero mean and unitary\n",
      " variance.\n",
      "************************************************************************************************\n"
     ]
    }
   ],
   "source": [
    "print (\"\\n\")\n",
    "print(\"************************************************************************************************\")\n",
    "print(\"This scripts computes the correlation between two monovariate signals.\"\n",
    "       \"First input is a sinewave of 1 Hz frequency, the second one\\n is the sum of this sinewave\"\n",
    "       \"with a gaussian random process having zero mean and unitary\\n variance.\")\n",
    "print(\"************************************************************************************************\")\n",
    "\n",
    "\"\"\" Import wanted module with every parent packages \"\"\"\n",
    "import Methods.DataFrom2Persons.Univariate.Continuous.Linear.Correlation as Correlation\n",
    "\n",
    "\"\"\" Import Utils modules \"\"\"\n",
    "from Methods.utils import Standardize\n",
    "from Methods.utils.ExtractSignal import ExtractSignalFromCSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "An instance the class is now created with the following parameters:\n",
      "tau max = 999\n",
      "plot = True\n",
      "standardization= True\n",
      "corr_tau_max = True\n",
      "corr_coeff =True\n",
      "scale =True\n",
      "\n",
      "\n",
      "Computing...\n",
      "\n",
      "\n",
      "**************************************** \n",
      "\n",
      "Correlation complete result :\n",
      "****************************************\n",
      "\n",
      "Correlation function array:\n",
      "[ 0.00055833  0.00057387  0.00060354 ... -0.00013203 -0.00017167\n",
      " -0.00013097]\n",
      "Maximum value of the correlation 0.012818 and lag (in samples) -383:\n",
      "Pearson's correlation coefficient 0.066050:\n"
     ]
    }
   ],
   "source": [
    "\"\"\" Define signals in pd.dataFrame format \"\"\"\n",
    "\n",
    "#Define parameters\n",
    "N=1024 # number of samples\n",
    "f=1.0  # sinewave frequency (Hz)\n",
    "Fs=200 # sampling frequency (Hz)\n",
    "\n",
    "n=np.arange(0,N)#number of samples\n",
    "\n",
    "# Create signals\n",
    "x = pd.DataFrame({'X':np.sin(2*3.14*f*n/Fs)}, np.arange(0,N))\n",
    "y = pd.DataFrame({'Y':np.sin(2*3.14*f*n/Fs)+10*np.random.randn(1,N)[0]},np.arange(0,N))\n",
    "\n",
    "'''\n",
    "\"\"\"OR\"\"\"\n",
    "\"\"\" Import signals from a .csv file \"\"\"\n",
    "#Data from files\n",
    "filename = 'data_examples/2Persons_Monovariate_Continuous_data.csv'\n",
    "\n",
    "x = ExtractSignalFromCSV(filename, columns = ['x1'])\n",
    "y = ExtractSignalFromCSV(filename, columns = ['x2'])\n",
    "n=np.arange(0,x.shape[0])\n",
    "'''\n",
    "\n",
    "\n",
    "\n",
    "\"\"\"Plot input signals\"\"\"\n",
    "plt.ion()\n",
    "f, axarr = plt.subplots(2, sharex=True)\n",
    "axarr[0].set_title('Input signals')\n",
    "axarr[0].set_xlabel('Samples')\n",
    "axarr[1].set_xlabel('Samples')\n",
    "\n",
    "axarr[0].plot(n, x, label=\"x\")\n",
    "axarr[1].plot(n, y, label=\"y\", color='r')\n",
    "axarr[0].legend(loc='best')\n",
    "axarr[1].legend(loc='best')\n",
    "\n",
    "\n",
    "\n",
    "\"\"\" Define class attributes of the wanted method \"\"\"\n",
    "\n",
    "tau_max = 999                       # the maximum lag at which correlation should be computed (in samples)\n",
    "plot=True                           # plot of the correlation fucntion\n",
    "standardization = True              # standardization of the time series to mean 0 and variance 1\n",
    "corr_tau_max = True                 # return of the maximum of correlation and its lag\n",
    "corr_coeff = True                   # computation of the correlation coefficient (Pearson's version)\n",
    "scale=True                          # scale factor to have correlaton in [-1,1]\n",
    "\n",
    "\"\"\" Instanciate the class with its attributes \"\"\"\n",
    "print(\"\\n\")\n",
    "\n",
    "try : \n",
    "    c=Correlation.Correlation(tau_max, plot, standardization, corr_tau_max, corr_coeff, scale)\n",
    "except TypeError as err :\n",
    "    print(\"TypeError in Correlation constructor : \\n\" + str(err))\n",
    "    sys.exit(-1)\n",
    "except ValueError as err :\n",
    "    print(\"ValueError in Correlation constructor : \\n\" + str(err))\n",
    "    sys.exit(-1)\n",
    "except Exception as e :\n",
    "    print(\"Exception in Correlation constructor : \\n\" + str(e))\n",
    "    sys.exit(-1)\n",
    "\n",
    "print(\"An instance the class is now created with the following parameters:\\n\" +\n",
    "      \"tau max = \" + str(tau_max) + \"\\n\" +\n",
    "      \"plot = \" + str(plot) + \"\\n\" +\n",
    "      \"standardization= \" + str(standardization) + \"\\n\" +\n",
    "      \"corr_tau_max = \" + str(corr_tau_max) + \"\\n\" +\n",
    "      \"corr_coeff =\" + str(corr_coeff) +\"\\n\" +\n",
    "      \"scale =\" + str(scale))\n",
    "\n",
    "\"\"\" Compute the method and get the result \"\"\"\n",
    "print(\"\\n\")\n",
    "print(\"Computing...\")\n",
    "\n",
    "try : \n",
    "    res= c.compute([x, y])\n",
    "except TypeError as err :\n",
    "    print(\"TypeError in Correlation computation : \\n\" + str(err))\n",
    "    sys.exit(-1)\n",
    "except ValueError as err :\n",
    "    print(\"ValueError in Correlation computation : \\n\" + str(err))\n",
    "    sys.exit(-1)\n",
    "except Exception as e :\n",
    "    print(\"Exception in Correlation computation : \\n\" + str(e))\n",
    "    sys.exit(-1)\n",
    "\n",
    "\"\"\" Display result \"\"\"\n",
    "print(\"\\n\")\n",
    "print(\"**************************************** \\n\")\n",
    "print('Correlation complete result :')\n",
    "print(\"****************************************\\n\")\n",
    "print(\"Correlation function array:\")\n",
    "print(res['corr_funct'])\n",
    "print(\"Maximum value of the correlation %f and lag (in samples) %d:\" %(res['max_corr'],res['t_max']))\n",
    "print(\"Pearson's correlation coefficient %f:\" %(res['corr_coeff']))\n",
    "\n",
    "\n",
    "plt.close(\"all\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
