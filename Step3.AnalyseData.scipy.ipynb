{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Video Actor Synchroncy and Causality (VASC)\n",
    "## RAEng: Measuring Responsive Caregiving Project\n",
    "### Caspar Addyman, 2020\n",
    "### https://github.com/infantlab/VASC\n",
    "\n",
    "# Step 3: Analyse the data using scipy statsmodels\n",
    "\n",
    "This script correlates and compares the timeseries of wireframes for the two figures in the video `[\"parent\", \"infant\"]`\n",
    "\n",
    "We start by reloading the saved parquet file containing the multi-index numpy array of all [OpenPose](https://github.com/CMU-Perceptual-Computing-Lab/openpose) data from all pairs of individuals. \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import json\n",
    "import math\n",
    "import numpy as np       \n",
    "import pandas as pd\n",
    "import pyarrow.parquet as pq\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import logging\n",
    "import ipywidgets as widgets  #let's us add buttons and sliders to this page.\n",
    "from ipycanvas import Canvas\n",
    "\n",
    "import vasc #a module of our own functions (found in vasc.py in this folder)\n",
    "\n",
    "#turn on debugging\n",
    "logger = logging.getLogger()\n",
    "logger.setLevel(logging.INFO)\n",
    "%pdb on"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "jupwd =  os.getcwd() + \"\\\\\"\n",
    "# where's the project data folder? \n",
    "projectpath = \"C:\\\\Users\\\\cas\\\\OneDrive - Goldsmiths College\\\\Projects\\\\Measuring Responsive Caregiving\\\\VASCTutorial\"\n",
    "#where are your video files? \n",
    "videos_in = \"C:\\\\Users\\\\cas\\\\OneDrive - Goldsmiths College\\\\Projects\\\\Measuring Responsive Caregiving\\\\VASCTutorial\\\\demovideos\"\n",
    "\n",
    "\n",
    "# locations of videos and output\n",
    "videos_out   = projectpath + \"\\\\out\"\n",
    "videos_out_openpose   = videos_out + \"\\\\openpose\"\n",
    "videos_out_timeseries = videos_out + \"\\\\timeseries\"\n",
    "videos_out_analyses   = videos_out + \"\\\\analyses\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 Load the clean data as a DataFrame\n",
    "\n",
    "Reload the clean data file created in step 2. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#retrieve the list of base names of processed videos.\n",
    "try:\n",
    "    with open(videos_out + '\\\\clean.json') as json_file:\n",
    "        videos = json.load(json_file)\n",
    "        print(\"Existing clean.json found..\")\n",
    "except:\n",
    "    print(\"File clean.json not found.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('reading parquet file:')\n",
    "df = pq.read_table(videos_out_timeseries + '\\\\cleandata.parquet').to_pandas()\n",
    "\n",
    "#sort the column names as this helps with indexing\n",
    "df = df.sort_index(axis = 1)\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.2 Process the data \n",
    "\n",
    "Next we set all 0 values to as missing value `np.nan` to enable interpolation.\n",
    "Then use numpy's built in `interpolate` method. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.replace(0.0, np.nan)\n",
    "\n",
    "#are we going to use all the data or a subset?\n",
    "first = 0\n",
    "last = 8500\n",
    "\n",
    "df = df.truncate(before  = first, after = last)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.interpolate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#take a quick look\n",
    "print(df.head())\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2.1 Mean movements\n",
    "We create a dictionary of the subsets of OpenPose coordinates we want to average and then call `mean` on the Pandas dataframe. e.g.\n",
    "\n",
    "```\n",
    "meanpoints = {\n",
    "               \"headx\" : [0, 3, 45, 48, 51, 54],\n",
    "               \"heady\" : [1, 4, 46, 49, 52, 55],\n",
    "               \"allx\" :  [0, 3, 6, 9, ...],\n",
    "               \"ally\" :  [1, 4, 7, 10, ...]\n",
    "             }\n",
    "```\n",
    "\n",
    "Then we call the `vasc.averageCoordinateTimeSeries` function to average across sets of coordinates. For a given set of videos and people. For example\n",
    "\n",
    "In:\n",
    "```\n",
    "videos = \"All\"\n",
    "people = \"Both\"\n",
    "df2 = vasc.averageCoordinateTimeSeries(df,meanpoints,videos,people)\n",
    "df2.head\n",
    "```\n",
    "\n",
    "Out:\n",
    "```\n",
    "person      infant                                          parent   \n",
    "avgs         headx       heady          xs          ys       headx   \n",
    "501     565.996600  369.840600  534.895615  398.482538  471.686200   \n",
    "502     567.231800  369.887600  534.354198  398.706552  471.849400   \n",
    "503     567.228600  370.159600  534.444328  398.678133  471.711600   \n",
    "504     566.912600  369.857000  535.369536  398.551636  472.309400\n",
    "...            ...         ...         ...         ...         ...\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "meanpoints = {\"head\" : vasc.headxys,\n",
    "              \"headx\": vasc.headx,\n",
    "              \"heady\": vasc.heady,\n",
    "              \"arms\" : vasc.armsxys,\n",
    "              \"armsx\": vasc.armsx,\n",
    "              \"armsy\": vasc.armsy,\n",
    "              \"all\"  : vasc.xys,\n",
    "              \"allx\" : vasc.xs,\n",
    "              \"ally\" : vasc.ys}\n",
    "\n",
    "vids = \"All\"\n",
    "people = [\"infant\",\"parent\"]\n",
    "\n",
    "#average across the points in each group (all points of head etc. )\n",
    "avgdf = vasc.averageCoordinateTimeSeries(df,meanpoints,vids,people)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "avgdf.head"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2.2 Rolling window of movements\n",
    "\n",
    "One thing we'd like to know is if mothers move in response to infants. The raw time series are probably too noisy to tell us this so instead we can look at few alternatives\n",
    "\n",
    "1. **Smoothed** - if we average the signal over a short rolling window we smooth out any high-frequency jitter. \n",
    "2. **Variance** - the variance of movement over a short rolling window. First we apply 2 second long (50 frame) rolling window to each coordinate of the body and use the stddev or variance function `std()` or `var()` . Then we take averages as in the step above. However, this time we combine x and y coordinates as this is now a movement index.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "win = 50 #2 seconds\n",
    "halfwin = math.floor(win/2)\n",
    "\n",
    "smoothdf = df.rolling(window = 5).mean()\n",
    "smoothdf = smoothdf.truncate(before  = first, after = last)\n",
    "\n",
    "vardf = df.rolling(window = win, min_periods = halfwin).var()\n",
    "vardf = vardf.truncate(before  = first + 50, after = last) # cut out the empty bits at the start\n",
    " \n",
    "smoothdf = vasc.averageCoordinateTimeSeries(smoothdf,meanpoints,vids,people)\n",
    "vardf = vasc.averageCoordinateTimeSeries(vardf,meanpoints,vids,people)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's create a widget to plot some graphs of the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 0
   },
   "outputs": [],
   "source": [
    "vidlist = [] #used to fill dropdown options\n",
    "for vid in videos:  \n",
    "    vidlist.append(vid)\n",
    "        \n",
    "pickvid = widgets.Dropdown(\n",
    "    options= vidlist,\n",
    "    value= vidlist[0],\n",
    "    description='Subject:'\n",
    ")\n",
    "\n",
    "features = []\n",
    "for f in meanpoints:\n",
    "    features.append(f)\n",
    "    \n",
    "pickfeature = widgets.Dropdown(\n",
    "    options= features,\n",
    "    value= features[0],\n",
    "    description='Feature:'\n",
    ")\n",
    "\n",
    "linetypes = [\"Mean point\", \"Smoothed Mean (5 frames)\",\"Variance over 2 secs\"]\n",
    "picktype = widgets.Dropdown(\n",
    "    options= linetypes,\n",
    "    value= linetypes[0],\n",
    "    description='Line type:'\n",
    ")\n",
    "\n",
    "def pickvid_change(change):\n",
    "    if change['name'] == 'value' and (change['new'] != change['old']):\n",
    "        updateAll(True)\n",
    "        \n",
    "def pickfeature_change(change):\n",
    "    if change['name'] == 'value' and (change['new'] != change['old']):\n",
    "        updateAll(True)\n",
    "\n",
    "def picktype_change(change):\n",
    "    if change['name'] == 'value' and (change['new'] != change['old']):\n",
    "        updateAll(True)\n",
    "        \n",
    "pickvid.observe(pickvid_change, 'value') \n",
    "pickfeature.observe(pickfeature_change, 'value') \n",
    "picktype.observe(picktype_change, 'value') \n",
    "button_update = widgets.Button(description=\"Redraw\")\n",
    "output = widgets.Output()\n",
    "\n",
    "\n",
    "def drawGraphs(vid, feature, linetype):\n",
    "    \"\"\"Plot input signals\"\"\"\n",
    "    plt.ion()\n",
    "\n",
    "    f,ax=plt.subplots(4,1,figsize=(14,10),sharex=True)\n",
    "    ax[0].set_title('Infant')\n",
    "    ax[1].set_title('Parent')\n",
    "    ax[1].set_xlabel('Frames')\n",
    "\n",
    "    who = [\"infant\",\"parent\"]\n",
    "\n",
    "    if linetype == linetypes[0]:\n",
    "        usedf = avgdf\n",
    "    elif linetype == linetypes[1]:\n",
    "        usedf = smoothdf\n",
    "    else:\n",
    "        usedf = vardf\n",
    "        \n",
    "    #to select a single column..\n",
    "    infant = usedf[(vid, people[0], feature)].to_frame()\n",
    "    parent = usedf[(vid, people[1], feature)].to_frame()\n",
    "    n  = np.arange(usedf.shape[0])\n",
    "    \n",
    "    #selecting multiple columns slightly messier\n",
    "    #infant = df3.loc[50:,(vid, part[0], ('head','arms', 'all'))]\n",
    "    #parent = df3.loc[50:,(vid, part[1], ('head','arms', 'all'))]\n",
    "\n",
    "    ax[0].plot(n,infant)\n",
    "    ax[1].plot(n,parent, color='b')\n",
    "    \n",
    "    #calculate the correlations in a shorter rolling window\n",
    "    r_window_size = 120\n",
    "    rolling_r = usedf[(vid, who[0], feature)].rolling(window=r_window_size, center=True).corr(vardf[(vid, who[1], feature)])\n",
    "\n",
    "\n",
    "    usedf.loc[:,(vid, slice(None), feature)].plot(ax=ax[2])\n",
    "    ax[2].set(xlabel='Frame',ylabel='Movement index for parent and infant')\n",
    "\n",
    "    rolling_r.plot(ax=ax[3])\n",
    "    ax[3].set(xlabel='Frame',ylabel='Pearson r')\n",
    "    ax[3].set_title(\"Local correlation with rolling window size \" + str(r_window_size))\n",
    "\n",
    "    plt.show() \n",
    "\n",
    "def updateAll(forceUpdate = False):\n",
    "    output.clear_output(wait = True)\n",
    "    if forceUpdate:\n",
    "        logging.debug('forceUpdate')\n",
    "        #slider.value = 0\n",
    "        #slider.max = videos[pickvid.value][pickcam.value][\"end\"]\n",
    "    with output:\n",
    "        display(pickvid,pickfeature,picktype,button_update)  \n",
    "        drawGraphs(pickvid.value,pickfeature.value,picktype.value)\n",
    "    \n",
    "#draw everything for first time\n",
    "updateAll(True)\n",
    "output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3 Movement analysis\n",
    "\n",
    "First we run some simple correlations between the mother and infant."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "infant = vardf[(vid, people[0], 'head')].to_frame()\n",
    "infant.head\n",
    "print(type(infant))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#vid = \"SS003\"\n",
    "vardf[(vid, people[0], 'head')].corr(vardf[(vid, people[1], 'head')]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "who = [\"infant\",\"parent\"]\n",
    "parts = [\"head\",\"arms\",\"all\"]\n",
    "results = pd.DataFrame(columns = (\"corrHead\",\"lagHead\",\"corrArms\",\"lagArms\",\"corrAll\",\"lagAll\",\"DyadSynScore\"),\n",
    "                      index = videos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#loop through colculate for each pair\n",
    "for vid in videos:\n",
    "    thisrow = []\n",
    "    for part in parts:\n",
    "        #to select a single column..\n",
    "        pearson = vardf[(vid, people[0], part)].corr(vardf[(vid, people[1], part)])\n",
    " \n",
    "        thisrow.append(pearson) #this is for correlation\n",
    "        thisrow.append(None) #this is for maximum lag\n",
    "    \n",
    "    thisrow.append(None) #don't have DyadSynScore yet \n",
    "    results.loc[vid] = thisrow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#take a quick look\n",
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.4 Comparing to human coding. \n",
    "\n",
    "We have a spreadsheet of syhnchrony scores for each parent infant dyad. Here we see if we can find a measure that correlates with the human scores.\n",
    "\n",
    "First, load up the spreadsheet.."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "excelpath = projectpath + \"\\\\SS_CARE.xlsx\"\n",
    "\n",
    "filename, file_format = os.path.splitext(excelpath)\n",
    "if file_format and file_format == 'xls':\n",
    "    # use default reader \n",
    "    videolist = pd.read_excel(excelpath)\n",
    "else: \n",
    "    #since dec 2020 read_excel no longer supports xlsx (!?) so need to use openpyxl like so..\n",
    "    videolist = pd.read_excel(excelpath, engine = \"openpyxl\")\n",
    "    \n",
    "videolist = videolist.set_index(\"subject\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#take a quick look\n",
    "videolist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#copy the dyad syncrhony and maternal sensitivity scores into our data frame.\n",
    "results[\"DyadSynScore\"] = videolist[\"DyadSyn\"]\n",
    "results[\"MatSensScore\"] = videolist[\"MatSens\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#take a quick look\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#scatter plots of these results. \n",
    "plt.scatter(results[\"DyadSynScore\"],results[\"corrArms\"], )\n",
    "plt.title(\"Correlation between expert rated synchrony and time series correlations\")\n",
    "plt.xlabel(\"Dyad Synchroncy Score\")\n",
    "plt.ylabel(\"Dyad Correlation\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rolling_r.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "d1 = vardf[(vid, who[0], parts[0])]\n",
    "d2 = vardf[(vid, who[1], parts[0])]\n",
    "seconds = 5\n",
    "fps = 25\n",
    "wholeads = who[0] + 'leads <> ' + who[1] + ' leads'\n",
    "rs = [vasc.crosscorr(d1,d2, lag) for lag in range(-int(seconds*fps-1),int(seconds*fps))]\n",
    "offset = np.ceil(len(rs)/2)-np.argmax(rs)\n",
    "f,ax=plt.subplots(figsize=(14,3))\n",
    "ax.plot(rs)\n",
    "ax.axvline(np.ceil(len(rs)/2),color='k',linestyle='--',label='Center')\n",
    "ax.axvline(np.argmax(rs),color='r',linestyle='--',label='Peak synchrony')\n",
    "ax.set(title=f'Offset = {offset} frames\\n' + wholeads,ylim=[.0,1],xlim=[0,300], xlabel='Offset',ylabel='Pearson r')\n",
    "ax.set_xticklabels([int(item-150) for item in ax.get_xticks()]);\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.4 Granger Causality\n",
    "\n",
    "The next thing to look at is if the movements of the infant predict the movements of the parent. This would suggest parent is responding to the infant. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 0
   },
   "outputs": [],
   "source": [
    "\n",
    "https://towardsdatascience.com/granger-causality-and-vector-auto-regressive-model-for-time-series-forecasting-3226a64889a6\n",
    "\n",
    "https://www.machinelearningplus.com/time-series/time-series-analysis-python/\n",
    "    \n",
    "https://towardsdatascience.com/four-ways-to-quantify-synchrony-between-time-series-data-b99136c4a9c9\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "jupytext": {
   "formats": "ipynb,py:light"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
