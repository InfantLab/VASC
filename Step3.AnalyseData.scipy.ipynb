{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Video Actor Synchroncy and Causality (VASC)\n",
    "## RAEng: Measuring Responsive Caregiving Project\n",
    "### Caspar Addyman, 2020\n",
    "### https://github.com/infantlab/VASC\n",
    "\n",
    "# Step 3: Analyse the data using statsmodels\n",
    "\n",
    "This script correlates and compares the timeseries of wireframes for the two figures in the video `[\"parent\", \"infant\"]`\n",
    "\n",
    "We start by reloading the saved parquet file containing the numpy array of all [OpenPose](https://github.com/CMU-Perceptual-Computing-Lab/openpose) data from all pairs of individuals. \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Automatic pdb calling has been turned ON\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "import json\n",
    "import math\n",
    "import numpy as np       \n",
    "import pandas as pd\n",
    "import pyarrow.parquet as pq\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import logging\n",
    "import ipywidgets as widgets  #let's us add buttons and sliders to this page.\n",
    "from ipycanvas import Canvas\n",
    "\n",
    "import vasc #a module of our own functions (found in vasc.py in this folder)\n",
    "\n",
    "#turn on debugging\n",
    "logger = logging.getLogger()\n",
    "logger.setLevel(logging.INFO)\n",
    "%pdb on"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "jupwd =  os.getcwd() + \"\\\\\"\n",
    "projectpath = os.getcwd() + \"\\\\..\\\\SpeakNSign\\\\\"\n",
    "# projectpath = os.getcwd() + \"\\\\..\\\\lookit\\\\\"\n",
    "\n",
    "# locations of videos and output\n",
    "videos_in = projectpath \n",
    "videos_out   = projectpath + \"out\"\n",
    "#videos_out = \"E:\\\\SpeakNSign\\\\out\"\n",
    "videos_out_openpose   = videos_out + \"\\\\openpose\"\n",
    "videos_out_timeseries = videos_out + \"\\\\timeseries\"\n",
    "videos_out_analyses   = videos_out + \"\\\\analyses\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 Load the clean data as a DataFrame\n",
    "\n",
    "Reload the clean data file created in step 2. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Existing clean.json found..\n"
     ]
    }
   ],
   "source": [
    "#retrieve the list of base names of processed videos.\n",
    "try:\n",
    "    with open(videos_out + '\\\\clean.json') as json_file:\n",
    "        videos = json.load(json_file)\n",
    "        print(\"Existing clean.json found..\")\n",
    "except:\n",
    "    print(\"File clean.json not found.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reading parquet file:\n",
      "video     SS003                                                          \\\n",
      "person   infant                                                           \n",
      "coord        0        1         2        3        4         5        6    \n",
      "0       556.540  356.132  0.899432  555.002  395.181  0.469440  547.184   \n",
      "1       555.026  356.080  0.761866  556.577  390.507  0.352666  545.625   \n",
      "2         0.000    0.000  0.000000    0.000    0.000  0.000000    0.000   \n",
      "3       556.507  354.526  0.722555  553.467  395.316  0.331564  556.561   \n",
      "4         0.000    0.000  0.000000    0.000    0.000  0.000000    0.000   \n",
      "\n",
      "video                               ...  SS098                                \\\n",
      "person                              ... parent                                 \n",
      "coord        7         8        9   ...     65   66   67   68   69   70   71   \n",
      "0       382.758  0.336208  515.839  ...    0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
      "1       379.606  0.275334  531.538  ...    0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
      "2         0.000  0.000000    0.000  ...    0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
      "3       392.110  0.232135    0.000  ...    0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
      "4         0.000  0.000000    0.000  ...    0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
      "\n",
      "video                               \n",
      "person                              \n",
      "coord        72       73        74  \n",
      "0         0.000    0.000  0.000000  \n",
      "1       437.546  370.185  0.108079  \n",
      "2         0.000    0.000  0.000000  \n",
      "3         0.000    0.000  0.000000  \n",
      "4         0.000    0.000  0.000000  \n",
      "\n",
      "[5 rows x 7950 columns]\n"
     ]
    }
   ],
   "source": [
    "print('reading parquet file:')\n",
    "df = pq.read_table(videos_out_timeseries + '\\\\cleandata.parquet').to_pandas()\n",
    "\n",
    "#sort the column names as this helps with indexing\n",
    "df = df.sort_index(axis = 1)\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.2 Process the data \n",
    "\n",
    "Next we set all 0 values to as missing value `np.nan` to enable interpolation.\n",
    "Then use numpy's built in `interpolate` method. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.replace(0.0, np.nan)\n",
    "\n",
    "#are we going to use all the data or a subset?\n",
    "first = 501\n",
    "last = 8500\n",
    "\n",
    "df = df.truncate(before  = first, after = last)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.interpolate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8000, 7950)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "video     SS003                                                          \\\n",
      "person   infant                                                           \n",
      "coord        0        1         2        3        4         5        6    \n",
      "501     559.714  357.592  0.787151  555.025  396.784  0.356000  555.002   \n",
      "502     559.765  357.602  0.839487  556.574  398.406  0.373636  559.706   \n",
      "503     559.783  357.606  0.777033  556.540  396.856  0.284398  558.187   \n",
      "504     559.736  357.585  0.785370  556.574  398.360  0.346349  558.166   \n",
      "505     559.691  357.645  0.834648  556.556  396.822  0.363410  558.152   \n",
      "\n",
      "video                                  ...  SS098                              \\\n",
      "person                                 ... parent                               \n",
      "coord        7         8           9   ...     65  66  67  68  69  70  71  72   \n",
      "501     393.608  0.236688  512.724000  ...    NaN NaN NaN NaN NaN NaN NaN NaN   \n",
      "502     395.207  0.250447  513.843571  ...    NaN NaN NaN NaN NaN NaN NaN NaN   \n",
      "503     393.708  0.188241  514.963143  ...    NaN NaN NaN NaN NaN NaN NaN NaN   \n",
      "504     393.676  0.233328  516.082714  ...    NaN NaN NaN NaN NaN NaN NaN NaN   \n",
      "505     392.121  0.228091  517.202286  ...    NaN NaN NaN NaN NaN NaN NaN NaN   \n",
      "\n",
      "video           \n",
      "person          \n",
      "coord   73  74  \n",
      "501    NaN NaN  \n",
      "502    NaN NaN  \n",
      "503    NaN NaN  \n",
      "504    NaN NaN  \n",
      "505    NaN NaN  \n",
      "\n",
      "[5 rows x 7950 columns]\n"
     ]
    }
   ],
   "source": [
    "print(df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2.1 Mean movements\n",
    "We create a dictionary of the subsets of OpenPose coordinates we want to average and then call `mean` on the Pandas dataframe. e.g.\n",
    "\n",
    "```\n",
    "meanpoints = {\n",
    "               \"headx\" : [0, 3, 45, 48, 51, 54],\n",
    "               \"heady\" : [1, 4, 46, 49, 52, 55],\n",
    "               \"allx\" :  [0, 3, 6, 9, ...],\n",
    "               \"ally\" :  [1, 4, 7, 10, ...]\n",
    "             }\n",
    "```\n",
    "\n",
    "Then we call the `vasc.averageCoordinateTimeSeries` function to average across sets of coordinates. For a given set of videos and people. For example\n",
    "\n",
    "In:\n",
    "```\n",
    "videos = \"All\"\n",
    "people = \"Both\"\n",
    "df2 = vasc.averageCoordinateTimeSeries(df,meanpoints,videos,people)\n",
    "df2.head\n",
    "```\n",
    "\n",
    "Out:\n",
    "```\n",
    "person      infant                                          parent   \n",
    "avgs         headx       heady          xs          ys       headx   \n",
    "501     565.996600  369.840600  534.895615  398.482538  471.686200   \n",
    "502     567.231800  369.887600  534.354198  398.706552  471.849400   \n",
    "503     567.228600  370.159600  534.444328  398.678133  471.711600   \n",
    "504     566.912600  369.857000  535.369536  398.551636  472.309400\n",
    "...            ...         ...         ...         ...         ...\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "meanpoints = {\"head\" : vasc.headxys,\n",
    "              \"arms\" : vasc.armsxys,\n",
    "              \"all\"  : vasc.xys}\n",
    "\n",
    "vids = \"All\"\n",
    "people = [\"infant\",\"parent\"]\n",
    "\n",
    "avgdf = vasc.averageCoordinateTimeSeries(df,meanpoints,vids,people)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method NDFrame.head of video        SS003                                                  \\\n",
       "person      infant                              parent               \n",
       "avgs          head        arms         all        head        arms   \n",
       "501     467.918600  464.463600  466.689077  372.051200  385.703300   \n",
       "502     468.559700  463.025586  466.530375  371.981250  387.091400   \n",
       "503     468.694100  462.667971  466.561230  372.065400  386.469400   \n",
       "504     468.384800  463.712157  466.960586  371.916700  386.154500   \n",
       "505     468.539600  462.892543  466.821596  372.058800  386.155600   \n",
       "...            ...         ...         ...         ...         ...   \n",
       "8496    441.726583  437.275333  422.315400  373.840000  347.557679   \n",
       "8497    441.721500  438.857583  422.348700  373.705083  344.702215   \n",
       "8498    441.845083  436.504500  420.968060  374.350000  345.367750   \n",
       "8499    441.857000  437.139500  421.153880  374.486500  347.848917   \n",
       "8500    441.591833  439.633583  421.879260  373.043750  349.026167   \n",
       "\n",
       "video                    SS004                                      ...  \\\n",
       "person                  infant                              parent  ...   \n",
       "avgs           all        head        arms         all        head  ...   \n",
       "501     373.486000         NaN         NaN         NaN  409.061167  ...   \n",
       "502     373.530337  408.044333         NaN  408.044333  327.017498  ...   \n",
       "503     373.830978  416.602000  426.576375  417.606577  231.043873  ...   \n",
       "504     373.454326  417.944625  428.138500  413.566286  238.395466  ...   \n",
       "505     373.263261  416.589625  424.810750  402.737312  245.747059  ...   \n",
       "...            ...         ...         ...         ...         ...  ...   \n",
       "8496    345.172743  415.493500  420.181000  386.289600  141.601569  ...   \n",
       "8497    346.112986  416.126000  423.574750  389.749840  140.813107  ...   \n",
       "8498    349.921740  416.241750  421.369083  386.519830  136.970607  ...   \n",
       "8499    344.378300  415.988833  419.006833  386.909620  134.099533  ...   \n",
       "8500    344.206240  416.494250  422.398500  388.879420  130.840128  ...   \n",
       "\n",
       "video        SS097                                           SS098  \\\n",
       "person      infant      parent                              infant   \n",
       "avgs           all        head        arms         all        head   \n",
       "501     320.619429  122.093400  197.614933  194.497783  397.129900   \n",
       "502     320.822429  122.097675  197.882333  195.045257  396.987800   \n",
       "503     317.151336  122.278800  198.649792  195.877942  397.287700   \n",
       "504     315.201038  122.669850  199.035175  196.576786  397.127700   \n",
       "505     314.601832  122.702100  199.691775  197.627141  397.131800   \n",
       "...            ...         ...         ...         ...         ...   \n",
       "8496    303.413167  108.839450  206.476500  283.394614  378.131333   \n",
       "8497    303.954130  107.666542  206.234658  286.204916  377.769000   \n",
       "8498    303.271458  107.412942  206.356642  284.464706  377.888250   \n",
       "8499    302.740332  107.139450  205.968167  281.174948  377.769500   \n",
       "8500    302.551382  106.115400  205.326625  286.130916  377.227833   \n",
       "\n",
       "video                                                               \n",
       "person                              parent                          \n",
       "avgs          arms         all        head        arms         all  \n",
       "501     414.818583  416.923182  327.612500  328.070125  317.695227  \n",
       "502     414.556000  414.882318  327.126833  327.286125  318.486318  \n",
       "503     413.911333  413.078205  315.735000  327.090750  315.675125  \n",
       "504     413.772250  412.868572  315.523800  326.306125  315.472850  \n",
       "505     413.394167  412.233303  323.124680  326.714500  318.353421  \n",
       "...            ...         ...         ...         ...         ...  \n",
       "8496    395.507250  407.277773  306.289912  325.277083  300.540081  \n",
       "8497    391.981750  406.152420  310.451578  326.582917  302.942995  \n",
       "8498    391.066500  406.181600  312.679912  328.796833  303.311419  \n",
       "8499    392.900500  406.564580  316.068495  329.846500  304.655159  \n",
       "8500    392.249667  405.869320  317.248828  331.675417  305.788399  \n",
       "\n",
       "[8000 rows x 318 columns]>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "avgdf.head"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2.2 Rolling window of movements\n",
    "\n",
    "One thing we'd like to know is if mothers move in response to infants. The raw time series are probably too noisy to tell us this so instead we look at the variance of movement over a short rolling window. \n",
    "\n",
    "First we apply 2 second long (50 frame) rolling window to each coordinate of the body and use the stddev or variance function `std()` or `var()` . Then we take averages as in the step above. \n",
    "\n",
    "However, this time we combine x and y coordinates as this is now a movement index."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "win = 50\n",
    "\n",
    "movedf = df.rolling(window = win, min_periods = math.floor(win/2)).var()\n",
    "# cut out the empty bits at the start\n",
    "movedf = movedf.truncate(before  = first + 50, after = last)\n",
    "\n",
    "vids = \"All\"\n",
    "people = [\"infant\",\"parent\"]\n",
    "meanpoints = {\"head\" : vasc.headxys,\n",
    "              \"arms\" : vasc.armsxys,\n",
    "              \"all\"  : vasc.xys}\n",
    "\n",
    "movedf = vasc.averageCoordinateTimeSeries(movedf,meanpoints,vids,people)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "movedf.head"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's create a widget to plot some graphs of the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:forceUpdate\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cc7e97a8df46484d8c22e452b2633c05",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "vidlist = [] #used to fill dropdown options\n",
    "for vid in videos:  \n",
    "    vidlist.append(vid)\n",
    "        \n",
    "pickvid = widgets.Dropdown(\n",
    "    options= vidlist,\n",
    "    value= vidlist[0],\n",
    "    description='Subject:'\n",
    ")\n",
    "\n",
    "features = []\n",
    "for f in meanpoints:\n",
    "    features.append(f)\n",
    "    \n",
    "pickfeature = widgets.Dropdown(\n",
    "    options= features,\n",
    "    value= features[0],\n",
    "    description='Feature:'\n",
    ")\n",
    "\n",
    "linetypes = [\"Mean point\", \"Moving Average\"]\n",
    "picktype = widgets.Dropdown(\n",
    "    options= linetypes,\n",
    "    value= linetypes[0],\n",
    "    description='Line type:'\n",
    ")\n",
    "\n",
    "def pickvid_change(change):\n",
    "    if change['name'] == 'value' and (change['new'] != change['old']):\n",
    "        updateAll(True)\n",
    "        \n",
    "def pickfeature_change(change):\n",
    "    if change['name'] == 'value' and (change['new'] != change['old']):\n",
    "        updateAll(True)\n",
    "\n",
    "def picktype_change(change):\n",
    "    if change['name'] == 'value' and (change['new'] != change['old']):\n",
    "        updateAll(True)\n",
    "        \n",
    "pickvid.observe(pickvid_change, 'value') \n",
    "pickfeature.observe(pickfeature_change, 'value') \n",
    "picktype.observe(picktype_change, 'value') \n",
    "button_update = widgets.Button(description=\"Redraw\")\n",
    "output = widgets.Output()\n",
    "\n",
    "\n",
    "def drawGraphs(vid, feature, linetype):\n",
    "    \"\"\"Plot input signals\"\"\"\n",
    "    plt.ion()\n",
    "    f, axarr = plt.subplots(2, sharex=True)\n",
    "    axarr[0].set_title('Infant')\n",
    "    axarr[1].set_title('Parent')\n",
    "    #axarr[0].set_xlabel('Frames')\n",
    "    axarr[1].set_xlabel('Frames')\n",
    "\n",
    "    who = [\"infant\",\"parent\"]\n",
    "\n",
    "    if linetype == linetypes[0]:\n",
    "        usedf = avgdf\n",
    "    else:\n",
    "        usedf = movedf\n",
    "        \n",
    "    #to select a single column..\n",
    "    infant = usedf[(vid, who[0], feature)].to_frame()\n",
    "    parent = usedf[(vid, who[1], feature)].to_frame()\n",
    "    n  = np.arange(usedf.shape[0])\n",
    "    \n",
    "    #selecting multiple columns slightly messier\n",
    "    #infant = df3.loc[50:,(vid, part[0], ('head','arms', 'all'))]\n",
    "    #parent = df3.loc[50:,(vid, part[1], ('head','arms', 'all'))]\n",
    "\n",
    "    axarr[0].plot(n,infant , label=\"i\")\n",
    "    axarr[1].plot(n,parent, label=\"p\", color='b')\n",
    "    axarr[0].legend(loc='best')\n",
    "    axarr[1].legend(loc='best')\n",
    "\n",
    "    plt.show() \n",
    "\n",
    "def updateAll(forceUpdate = False):\n",
    "    output.clear_output(wait = True)\n",
    "    if forceUpdate:\n",
    "        logging.info('forceUpdate')\n",
    "        #slider.value = 0\n",
    "        #slider.max = videos[pickvid.value][pickcam.value][\"end\"]\n",
    "    with output:\n",
    "        display(pickvid,pickfeature,picktype,button_update)  \n",
    "        drawGraphs(pickvid.value,pickfeature.value,picktype.value)\n",
    "    \n",
    "#draw everything for first time\n",
    "updateAll(True)\n",
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3 Movement analysis\n",
    "\n",
    "First we run some simple correlations between the mother and infant."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "infant = movedf[(vid, who[0], 'head')].to_frame()\n",
    "infant.head\n",
    "print(type(infant))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vid = \"SS003\"\n",
    "movedf[(vid, who[0], 'head')].corr(movedf[(vid, who[1], 'head')]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "who = [\"infant\",\"parent\"]\n",
    "parts = [\"head\",\"arms\",\"all\"]\n",
    "results = pd.DataFrame(columns = (\"corrHead\",\"lagHead\",\"corrArms\",\"lagArms\",\"corrAll\",\"lagAll\",\"DyadSynScore\"),\n",
    "                      index = videos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#loop through colculate for each pair\n",
    "for vid in videos:\n",
    "    thisrow = []\n",
    "    for part in parts:\n",
    "        #to select a single column..\n",
    "        pearson = movedf[(vid, who[0], part)].corr(movedf[(vid, who[1], part)])\n",
    " \n",
    "        thisrow.append(pearson) #this is for correlation\n",
    "        thisrow.append(None) #this is for maximum lag\n",
    "    \n",
    "    thisrow.append(None) #don't have DyadSynScore yet \n",
    "    results.loc[vid] = thisrow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "excelpath = projectpath + \"\\\\SS_CARE.xlsx\"\n",
    "videolist = pd.read_excel(excelpath)\n",
    "videolist = videolist.set_index(\"subject\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "videolist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "results[\"DyadSynScore\"] = videolist[\"DyadSyn\"]\n",
    "results[\"MatSensScore\"] = videolist[\"MatSens\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vid = \"SS095\"\n",
    "# Set window size to compute moving window synchrony.\n",
    "r_window_size = 120\n",
    "# Compute rolling window synchrony\n",
    "\n",
    "#pearson = df3[(vid, who[0], part)].corr(df3[(vid, who[1], part)])\n",
    "rolling_r = df3[(vid, who[0], parts[0])].rolling(window=500, center=True).corr(df3[(vid, who[1], parts[1])])\n",
    "\n",
    "f,ax=plt.subplots(2,1,figsize=(14,6),sharex=True)\n",
    "df3.loc[:,(vid, slice(None), parts[0])].plot(ax=ax[0])\n",
    "ax[0].set(xlabel='Frame',ylabel='Movement index for parent and infant')\n",
    "rolling_r.plot(ax=ax[1])\n",
    "ax[1].set(xlabel='Frame',ylabel='Pearson r')\n",
    "plt.suptitle(\"Movement rolling window correlation\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rolling_r.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def crosscorr(datax, datay, lag=0, wrap=False):\n",
    "    \"\"\" Lag-N cross correlation. \n",
    "    Shifted data filled with NaNs \n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    lag : int, default 0\n",
    "    datax, datay : pandas.Series objects of equal length\n",
    "\n",
    "    Returns\n",
    "    ----------\n",
    "    crosscorr : float\n",
    "    \"\"\"\n",
    "    if wrap:\n",
    "        shiftedy = datay.shift(lag)\n",
    "        shiftedy.iloc[:lag] = datay.iloc[-lag:].values\n",
    "        return datax.corr(shiftedy)\n",
    "    else: \n",
    "        return datax.corr(datay.shift(lag))\n",
    "\n",
    "vid = \"SS095\"\n",
    "d1 = df3[(vid, who[0], parts[0])]\n",
    "d2 = df3[(vid, who[1], parts[0])]\n",
    "seconds = 5\n",
    "fps = 25\n",
    "wholeads = who[0] + 'leads <> ' + who[1] + ' leads'\n",
    "rs = [crosscorr(d1,d2, lag) for lag in range(-int(seconds*fps-1),int(seconds*fps))]\n",
    "offset = np.ceil(len(rs)/2)-np.argmax(rs)\n",
    "f,ax=plt.subplots(figsize=(14,3))\n",
    "ax.plot(rs)\n",
    "ax.axvline(np.ceil(len(rs)/2),color='k',linestyle='--',label='Center')\n",
    "ax.axvline(np.argmax(rs),color='r',linestyle='--',label='Peak synchrony')\n",
    "ax.set(title=f'Offset = {offset} frames\\n' + wholeads,ylim=[.0,1],xlim=[0,300], xlabel='Offset',ylabel='Pearson r')\n",
    "ax.set_xticklabels([int(item-150) for item in ax.get_xticks()]);\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.4 Granger Causality\n",
    "\n",
    "The next thing to look at is if the movements of the infant predict the movements of the parent. This would suggest parent is responding to the infant. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "https://towardsdatascience.com/granger-causality-and-vector-auto-regressive-model-for-time-series-forecasting-3226a64889a6\n",
    "\n",
    "https://www.machinelearningplus.com/time-series/time-series-analysis-python/\n",
    "    \n",
    "https://towardsdatascience.com/four-ways-to-quantify-synchrony-between-time-series-data-b99136c4a9c9\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
